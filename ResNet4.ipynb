{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "from tensorflow import Tensor\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sinkhorn_knopp import sinkhorn_knopp as skp\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "sk = skp.SinkhornKnopp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the objects:\n",
    "def savingResults(name, value):\n",
    "  # read all old results\n",
    "  with open('saved_historys.pkl', 'rb') as f:\n",
    "    allresults = pickle.load(f)\n",
    "  # append new resualt\n",
    "  savedvariable = {'Name' : name, 'value': value}\n",
    "  allresults.append(savedvariable)\n",
    "  \n",
    "  # save new results\n",
    "  with open('saved_historys.pkl', 'wb') as f:\n",
    "    pickle.dump(allresults, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-rc3\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "inputno = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    relu = ReLU()(inputs)\n",
    "    bn = BatchNormalization()(relu)\n",
    "    return bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def THz_RF(NRF, NTHzT, Nu):\n",
    "    alpha = 3.5\n",
    "    PR = 1\n",
    "    fcRF = 2.1 * 10**9;\n",
    "    GT = 1\n",
    "    GR = 1\n",
    "    c2 = (3 * 10 ** 8) ** 2\n",
    "    gammaI = c2 * GT * GR / (16 * math.pi**2 * fcRF**2)\n",
    "    \n",
    "    PT = 1\n",
    "    kf = 0.05\n",
    "    fcTH = 1.0 * 10**12;\n",
    "    GTT = 316.2;\n",
    "    GRR = 316.2;\n",
    "    thetabs = math.pi / 6\n",
    "    thetamt = math.pi / 6\n",
    "    FBS = thetabs / (2 * math.pi);\n",
    "    FMT = thetamt / (2 * math.pi);\n",
    "    gammaII = c2 * GTT * GRR / (16 * math.pi**2 * fcTH**2)\n",
    "    R_max = 100\n",
    "    Wt = 5 * 10^8\n",
    "    Wr = 40 * 10^6\n",
    "    \n",
    "    rue = R_max * np.sqrt(np.random.rand(Nu,1))\n",
    "    thetau = 2 * math.pi * np.random.rand(Nu,1)\n",
    "    Xu = np.multiply(rue, np.cos(thetau))\n",
    "    Yu = np.multiply(rue, np.sin(thetau))\n",
    "    \n",
    "    rTHzbs = R_max * np.sqrt(np.random.rand(NTHzT,1))\n",
    "    thetaTb = 2 * math.pi * np.random.rand(NTHzT,1)\n",
    "    Xb = np.multiply(rTHzbs, np.cos(thetaTb))\n",
    "    Yb = np.multiply(rTHzbs, np.sin(thetaTb))\n",
    "    \n",
    "    rRFzbs = R_max * np.sqrt(np.random.rand(NRF,1))\n",
    "    thetaRb = 2 * math.pi * np.random.rand(NRF,1)\n",
    "    Xrb = np.multiply(rRFzbs, np.cos(thetaRb))\n",
    "    Yrb = np.multiply(rRFzbs, np.sin(thetaRb))\n",
    "    \n",
    "    (Xmp_Tmat, Xp_Tmat) = np.meshgrid(Xu,Xb)\n",
    "    (Ymp_Tmat, Yp_Tmat) = np.meshgrid(Yu,Yb)\n",
    "    D_ue_Tbs = np.sqrt(np.power(Xmp_Tmat - Xp_Tmat, 2) + np.power(Ymp_Tmat - Yp_Tmat, 2))\n",
    "    \n",
    "    \n",
    "    (Xmp_Rmat, Xp_Rmat) = np.meshgrid(Xu,Xrb)\n",
    "    (Ymp_Rmat, Yp_Rmat) = np.meshgrid(Yu,Yrb)\n",
    "    D_ue_Rbs = np.sqrt(np.power(Xmp_Rmat-Xp_Rmat, 2) + np.power(Ymp_Rmat-Yp_Rmat, 2))\n",
    "    \n",
    "    fadeRand = np.random.exponential(scale = 1.0, size = (NRF, Nu))\n",
    "    SRF = gammaI * np.multiply(fadeRand, np.multiply(PR, np.power(D_ue_Rbs ,-alpha)))\n",
    "    NP = 10 ** (-12);\n",
    "    interf = np.tile(np.sum(SRF, 0), (NRF, 1)) - SRF\n",
    "    RPrAllu1 = np.divide(SRF, (NP+interf))\n",
    "    RPrAllu = np.divide(SRF, NP)\n",
    "    \n",
    "    fadeRand1 = np.random.exponential(scale = 1.0, size = (NTHzT, Nu))\n",
    "    temp = np.divide(np.exp(-kf * D_ue_Tbs), np.power(D_ue_Tbs ,2))\n",
    "    STHz = gammaII * np.multiply(fadeRand1, PT * temp)\n",
    "    interfT = np.tile(np.sum(STHz, 0), (NTHzT, 1)) - STHz\n",
    "    TPrAllu1 = np.divide(STHz, (NP+interfT))\n",
    "    TPrAllu = np.divide(STHz, NP)\n",
    "    \n",
    "    SINR_Matrix = np.divide(1, np.concatenate((RPrAllu1, TPrAllu1), axis = 0))\n",
    "    \n",
    "    return SINR_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "pika = 4\n",
    "RFBSs = 2\n",
    "THzBSs = 2\n",
    "Users=pika\n",
    "\n",
    "Iteration = 100000;\n",
    "Allcost_matrix = np.zeros(shape = (Iteration,pika,pika))\n",
    "AllAssignment = np.zeros(shape = (Iteration,pika))\n",
    "\n",
    "for i in range(Iteration):\n",
    "    cost_matrix = THz_RF(RFBSs, THzBSs, Users)\n",
    "#     cost_matrix = sk.fit(cost_matrix)\n",
    "#     cost_matrix = np.random.rand(Users, Users)\n",
    "    assignment = linear_sum_assignment(cost_matrix)[1];\n",
    "    \n",
    "    Allcost_matrix[i,:,:] = cost_matrix\n",
    "    AllAssignment[i,:] = assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_percentage = 0.9\n",
    "Val_percentage = 0.1\n",
    "\n",
    "x_data = np.expand_dims(Allcost_matrix,axis = 3)\n",
    "\n",
    "# x_data = 1/(np.log10(x_data + 1))\n",
    "x_data = np.log10(x_data) - 1\n",
    "# x_data = x_data - 0.5\n",
    "# x_data = 2*x_data\n",
    "\n",
    "y_data = np.expand_dims(AllAssignment[:,0],axis = 1)\n",
    "\n",
    "\n",
    "Total_data_No = y_data.shape[0]\n",
    "#Val_No = int(np.floor(Val_percentage*Total_data_No))\n",
    "Train_data_No = int(np.floor(Train_percentage*Total_data_No))\n",
    "# print(Total_data_No)\n",
    "# print(Train_data_No)\n",
    "y_test = y_data[Train_data_No:,:]\n",
    "y_train2 = y_data[:Train_data_No,:]\n",
    "\n",
    "\n",
    "x_test = x_data[Train_data_No:,:,:,:]\n",
    "x_train2 = x_data[:Train_data_No,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv2D(kernel_size= kernel_size,\n",
    "               strides= (1 if not downsample else 2),\n",
    "               filters=filters,\n",
    "               padding=\"same\")(x)\n",
    "    # y = relu_bn(y)\n",
    "    y = ReLU()(y)\n",
    "    \n",
    "    y = Conv2D(kernel_size= kernel_size,\n",
    "               strides=1,\n",
    "               filters=filters,\n",
    "               padding=\"same\")(y)\n",
    "               \n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,\n",
    "                   strides=2,\n",
    "                   filters=filters,\n",
    "                   padding=\"same\")(x)\n",
    "    out = Add()([x, y])\n",
    "    # out = relu_bn(out)\n",
    "    out = ReLU()(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_res_net():\n",
    "    \n",
    "    inputs = Input(shape=(inputno, inputno, 1))\n",
    "    num_filters = 32\n",
    "    \n",
    "    #t = BatchNormalization()(inputs)\n",
    "    #t = Conv2D(kernel_size=3,\n",
    "               #strides=1,\n",
    "               #filters=num_filters,\n",
    "               #padding=\"same\")(inputs)\n",
    "    #t = relu_bn(t)\n",
    "    #t= ReLU()(t)\n",
    "    t = inputs\n",
    "    num_blocks_list = [2]\n",
    "    for i in range(len(num_blocks_list)):\n",
    "      num_blocks = num_blocks_list[i]\n",
    "      for j in range(num_blocks):\n",
    "        t = residual_block(t, downsample= (j==0 and i!=0), filters=num_filters)\n",
    "        t = Dropout(0.1)(t)\n",
    "      num_filters *= 2\n",
    "    #num_filters1 = 16\n",
    "    #num_filters2 = 16\n",
    "    #t = residual_block(t, downsample=(False), filters=num_filters1)\n",
    "    #t = residual_block(t, downsample=(False), filters=num_filters2)\n",
    "\n",
    "    \n",
    "    #t = AveragePooling2D(4)(t)\n",
    "    t = Flatten()(t)\n",
    "#     t = Dropout(0.2)(t)\n",
    "#     m = Dense(32,activation = 'softmax')(t)\n",
    "#     t = Dropout(0.2)(t)\n",
    "    outputs = Dense(inputno, activation='softmax')(t)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    myopt = tf.keras.optimizers.Adam(\n",
    "      learning_rate=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "      name='Adam'\n",
    "                            )\n",
    "    model.compile(\n",
    "        optimizer= myopt,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 4, 4, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 4, 4, 32)     320         input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_95 (ReLU)                 (None, 4, 4, 32)     0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 4, 4, 32)     9248        re_lu_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 4, 4, 32)     0           input_25[0][0]                   \n",
      "                                                                 conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_96 (ReLU)                 (None, 4, 4, 32)     0           add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 4, 4, 32)     0           re_lu_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 4, 4, 32)     9248        dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_97 (ReLU)                 (None, 4, 4, 32)     0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 4, 4, 32)     9248        re_lu_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 4, 4, 32)     0           dropout_20[0][0]                 \n",
      "                                                                 conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_98 (ReLU)                 (None, 4, 4, 32)     0           add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 4, 4, 32)     0           re_lu_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 512)          0           dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 4)            2052        flatten_23[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 30,116\n",
      "Trainable params: 30,116\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "model = create_res_net() \n",
    "model.summary()\n",
    "\n",
    "timestr = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "name = 'Association'+timestr \n",
    "\n",
    "checkpoint_path = \"checkpoints/\"+name+\"/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "os.system('mkdir {}'.format(checkpoint_dir))\n",
    "\n",
    "# save model after each epoch\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1\n",
    ")\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir='tensorboard_logs/'+name,\n",
    "    histogram_freq=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "704/704 [==============================] - 5s 6ms/step - loss: 1.4104 - accuracy: 0.3676 - val_loss: 1.1548 - val_accuracy: 0.5106\n",
      "Epoch 2/700\n",
      "704/704 [==============================] - 5s 6ms/step - loss: 1.2027 - accuracy: 0.4766 - val_loss: 1.0374 - val_accuracy: 0.5939\n",
      "Epoch 3/700\n",
      "704/704 [==============================] - 5s 6ms/step - loss: 1.1049 - accuracy: 0.5336 - val_loss: 0.9549 - val_accuracy: 0.6321\n",
      "Epoch 4/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 1.0239 - accuracy: 0.5747 - val_loss: 0.8775 - val_accuracy: 0.6643\n",
      "Epoch 5/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.9476 - accuracy: 0.6072 - val_loss: 0.8092 - val_accuracy: 0.6823\n",
      "Epoch 6/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.8844 - accuracy: 0.6314 - val_loss: 0.7560 - val_accuracy: 0.7000\n",
      "Epoch 7/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.8400 - accuracy: 0.6471 - val_loss: 0.7171 - val_accuracy: 0.7098\n",
      "Epoch 8/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.8038 - accuracy: 0.6597 - val_loss: 0.6882 - val_accuracy: 0.7180\n",
      "Epoch 9/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.7760 - accuracy: 0.6675 - val_loss: 0.6666 - val_accuracy: 0.7232\n",
      "Epoch 10/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.7521 - accuracy: 0.6760 - val_loss: 0.6492 - val_accuracy: 0.7317\n",
      "Epoch 11/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.7326 - accuracy: 0.6829 - val_loss: 0.6354 - val_accuracy: 0.7349\n",
      "Epoch 12/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.7138 - accuracy: 0.6922 - val_loss: 0.6241 - val_accuracy: 0.7370\n",
      "Epoch 13/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.7015 - accuracy: 0.6968 - val_loss: 0.6132 - val_accuracy: 0.7418\n",
      "Epoch 14/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.6866 - accuracy: 0.7017 - val_loss: 0.6048 - val_accuracy: 0.7435\n",
      "Epoch 15/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.6751 - accuracy: 0.7075 - val_loss: 0.5960 - val_accuracy: 0.7489\n",
      "Epoch 16/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.6622 - accuracy: 0.7125 - val_loss: 0.5883 - val_accuracy: 0.7521\n",
      "Epoch 17/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.6575 - accuracy: 0.7126 - val_loss: 0.5815 - val_accuracy: 0.7549\n",
      "Epoch 18/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.6453 - accuracy: 0.7191 - val_loss: 0.5746 - val_accuracy: 0.7563\n",
      "Epoch 19/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.6354 - accuracy: 0.7236 - val_loss: 0.5681 - val_accuracy: 0.7602\n",
      "Epoch 20/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.6286 - accuracy: 0.7250 - val_loss: 0.5608 - val_accuracy: 0.7645\n",
      "Epoch 21/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.6185 - accuracy: 0.7317 - val_loss: 0.5549 - val_accuracy: 0.7663\n",
      "Epoch 22/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.6118 - accuracy: 0.7343 - val_loss: 0.5482 - val_accuracy: 0.7688\n",
      "Epoch 23/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.6046 - accuracy: 0.7366 - val_loss: 0.5420 - val_accuracy: 0.7709\n",
      "Epoch 24/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5975 - accuracy: 0.7407 - val_loss: 0.5361 - val_accuracy: 0.7720\n",
      "Epoch 25/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5902 - accuracy: 0.7442 - val_loss: 0.5298 - val_accuracy: 0.7765\n",
      "Epoch 26/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5844 - accuracy: 0.7463 - val_loss: 0.5245 - val_accuracy: 0.7813\n",
      "Epoch 27/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5780 - accuracy: 0.7488 - val_loss: 0.5193 - val_accuracy: 0.7826\n",
      "Epoch 28/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5706 - accuracy: 0.7529 - val_loss: 0.5141 - val_accuracy: 0.7843\n",
      "Epoch 29/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5648 - accuracy: 0.7548 - val_loss: 0.5076 - val_accuracy: 0.7860\n",
      "Epoch 30/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5595 - accuracy: 0.7580 - val_loss: 0.5030 - val_accuracy: 0.7904\n",
      "Epoch 31/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5558 - accuracy: 0.7575 - val_loss: 0.4979 - val_accuracy: 0.7909\n",
      "Epoch 32/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5503 - accuracy: 0.7609 - val_loss: 0.4930 - val_accuracy: 0.7938\n",
      "Epoch 33/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5441 - accuracy: 0.7641 - val_loss: 0.4890 - val_accuracy: 0.7942\n",
      "Epoch 34/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5392 - accuracy: 0.7672 - val_loss: 0.4837 - val_accuracy: 0.7949\n",
      "Epoch 35/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5322 - accuracy: 0.7689 - val_loss: 0.4789 - val_accuracy: 0.7981\n",
      "Epoch 36/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5297 - accuracy: 0.7724 - val_loss: 0.4749 - val_accuracy: 0.7993\n",
      "Epoch 37/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5239 - accuracy: 0.7725 - val_loss: 0.4710 - val_accuracy: 0.8024\n",
      "Epoch 38/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5193 - accuracy: 0.7755 - val_loss: 0.4663 - val_accuracy: 0.8046\n",
      "Epoch 39/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5152 - accuracy: 0.7789 - val_loss: 0.4628 - val_accuracy: 0.8060\n",
      "Epoch 40/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5137 - accuracy: 0.7778 - val_loss: 0.4595 - val_accuracy: 0.8056\n",
      "Epoch 41/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5090 - accuracy: 0.7807 - val_loss: 0.4558 - val_accuracy: 0.8090\n",
      "Epoch 42/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5056 - accuracy: 0.7828 - val_loss: 0.4524 - val_accuracy: 0.8091\n",
      "Epoch 43/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5031 - accuracy: 0.7822 - val_loss: 0.4494 - val_accuracy: 0.8115\n",
      "Epoch 44/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4984 - accuracy: 0.7841 - val_loss: 0.4458 - val_accuracy: 0.8126\n",
      "Epoch 45/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4948 - accuracy: 0.7865 - val_loss: 0.4428 - val_accuracy: 0.8141\n",
      "Epoch 46/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4911 - accuracy: 0.7888 - val_loss: 0.4392 - val_accuracy: 0.8142\n",
      "Epoch 47/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4884 - accuracy: 0.7896 - val_loss: 0.4362 - val_accuracy: 0.8152\n",
      "Epoch 48/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4840 - accuracy: 0.7928 - val_loss: 0.4336 - val_accuracy: 0.8190\n",
      "Epoch 49/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4823 - accuracy: 0.7924 - val_loss: 0.4298 - val_accuracy: 0.8185\n",
      "Epoch 50/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4778 - accuracy: 0.7950 - val_loss: 0.4270 - val_accuracy: 0.8198\n",
      "Epoch 51/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4758 - accuracy: 0.7955 - val_loss: 0.4243 - val_accuracy: 0.8221\n",
      "Epoch 52/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4731 - accuracy: 0.7972 - val_loss: 0.4213 - val_accuracy: 0.8230\n",
      "Epoch 53/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4696 - accuracy: 0.7982 - val_loss: 0.4186 - val_accuracy: 0.8251\n",
      "Epoch 54/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4665 - accuracy: 0.7994 - val_loss: 0.4165 - val_accuracy: 0.8260\n",
      "Epoch 55/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4648 - accuracy: 0.8017 - val_loss: 0.4134 - val_accuracy: 0.8264\n",
      "Epoch 56/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4610 - accuracy: 0.8035 - val_loss: 0.4110 - val_accuracy: 0.8276\n",
      "Epoch 57/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4594 - accuracy: 0.8042 - val_loss: 0.4089 - val_accuracy: 0.8308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4561 - accuracy: 0.8054 - val_loss: 0.4056 - val_accuracy: 0.8299\n",
      "Epoch 59/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4538 - accuracy: 0.8058 - val_loss: 0.4035 - val_accuracy: 0.8323\n",
      "Epoch 60/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4520 - accuracy: 0.8064 - val_loss: 0.4019 - val_accuracy: 0.8330\n",
      "Epoch 61/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4475 - accuracy: 0.8101 - val_loss: 0.3988 - val_accuracy: 0.8349\n",
      "Epoch 62/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4476 - accuracy: 0.8096 - val_loss: 0.3978 - val_accuracy: 0.8353\n",
      "Epoch 63/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4445 - accuracy: 0.8110 - val_loss: 0.3956 - val_accuracy: 0.8352\n",
      "Epoch 64/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4440 - accuracy: 0.8109 - val_loss: 0.3932 - val_accuracy: 0.8369\n",
      "Epoch 65/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4392 - accuracy: 0.8133 - val_loss: 0.3905 - val_accuracy: 0.8372\n",
      "Epoch 66/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4361 - accuracy: 0.8150 - val_loss: 0.3890 - val_accuracy: 0.8388\n",
      "Epoch 67/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4352 - accuracy: 0.8149 - val_loss: 0.3867 - val_accuracy: 0.8406\n",
      "Epoch 68/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4338 - accuracy: 0.8146 - val_loss: 0.3848 - val_accuracy: 0.8405\n",
      "Epoch 69/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4314 - accuracy: 0.8160 - val_loss: 0.3828 - val_accuracy: 0.8421\n",
      "Epoch 70/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4286 - accuracy: 0.8173 - val_loss: 0.3810 - val_accuracy: 0.8435\n",
      "Epoch 71/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4262 - accuracy: 0.8190 - val_loss: 0.3789 - val_accuracy: 0.8447\n",
      "Epoch 72/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4253 - accuracy: 0.8187 - val_loss: 0.3773 - val_accuracy: 0.8463\n",
      "Epoch 73/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4242 - accuracy: 0.8210 - val_loss: 0.3755 - val_accuracy: 0.8471\n",
      "Epoch 74/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4190 - accuracy: 0.8211 - val_loss: 0.3733 - val_accuracy: 0.8462\n",
      "Epoch 75/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4201 - accuracy: 0.8229 - val_loss: 0.3719 - val_accuracy: 0.8486\n",
      "Epoch 76/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4173 - accuracy: 0.8223 - val_loss: 0.3698 - val_accuracy: 0.8487\n",
      "Epoch 77/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4147 - accuracy: 0.8243 - val_loss: 0.3677 - val_accuracy: 0.8500\n",
      "Epoch 78/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4134 - accuracy: 0.8250 - val_loss: 0.3667 - val_accuracy: 0.8514\n",
      "Epoch 79/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4126 - accuracy: 0.8244 - val_loss: 0.3648 - val_accuracy: 0.8521\n",
      "Epoch 80/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4090 - accuracy: 0.8277 - val_loss: 0.3624 - val_accuracy: 0.8544\n",
      "Epoch 81/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4074 - accuracy: 0.8273 - val_loss: 0.3609 - val_accuracy: 0.8543\n",
      "Epoch 82/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4058 - accuracy: 0.8282 - val_loss: 0.3594 - val_accuracy: 0.8542\n",
      "Epoch 83/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4038 - accuracy: 0.8296 - val_loss: 0.3589 - val_accuracy: 0.8545\n",
      "Epoch 84/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4034 - accuracy: 0.8296 - val_loss: 0.3563 - val_accuracy: 0.8551\n",
      "Epoch 85/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.4008 - accuracy: 0.8311 - val_loss: 0.3550 - val_accuracy: 0.8561\n",
      "Epoch 86/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3988 - accuracy: 0.8318 - val_loss: 0.3533 - val_accuracy: 0.8567\n",
      "Epoch 87/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3956 - accuracy: 0.8332 - val_loss: 0.3519 - val_accuracy: 0.8583\n",
      "Epoch 88/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3945 - accuracy: 0.8340 - val_loss: 0.3509 - val_accuracy: 0.8590\n",
      "Epoch 89/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3933 - accuracy: 0.8329 - val_loss: 0.3493 - val_accuracy: 0.8593\n",
      "Epoch 90/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3907 - accuracy: 0.8349 - val_loss: 0.3479 - val_accuracy: 0.8587\n",
      "Epoch 91/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3920 - accuracy: 0.8346 - val_loss: 0.3461 - val_accuracy: 0.8601\n",
      "Epoch 92/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.3886 - accuracy: 0.8372 - val_loss: 0.3445 - val_accuracy: 0.8608\n",
      "Epoch 93/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.3892 - accuracy: 0.8358 - val_loss: 0.3432 - val_accuracy: 0.8625\n",
      "Epoch 94/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3858 - accuracy: 0.8376 - val_loss: 0.3409 - val_accuracy: 0.8631\n",
      "Epoch 95/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3842 - accuracy: 0.8384 - val_loss: 0.3394 - val_accuracy: 0.8638\n",
      "Epoch 96/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3830 - accuracy: 0.8383 - val_loss: 0.3386 - val_accuracy: 0.8638\n",
      "Epoch 97/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3835 - accuracy: 0.8374 - val_loss: 0.3374 - val_accuracy: 0.8632\n",
      "Epoch 98/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3811 - accuracy: 0.8390 - val_loss: 0.3362 - val_accuracy: 0.8659\n",
      "Epoch 99/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3792 - accuracy: 0.8413 - val_loss: 0.3345 - val_accuracy: 0.8652\n",
      "Epoch 100/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3772 - accuracy: 0.8422 - val_loss: 0.3332 - val_accuracy: 0.8656\n",
      "Epoch 101/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3765 - accuracy: 0.8422 - val_loss: 0.3319 - val_accuracy: 0.8677\n",
      "Epoch 102/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3768 - accuracy: 0.8412 - val_loss: 0.3310 - val_accuracy: 0.8676\n",
      "Epoch 103/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3738 - accuracy: 0.8430 - val_loss: 0.3298 - val_accuracy: 0.8684\n",
      "Epoch 104/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3719 - accuracy: 0.8435 - val_loss: 0.3278 - val_accuracy: 0.8676\n",
      "Epoch 105/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3737 - accuracy: 0.8428 - val_loss: 0.3278 - val_accuracy: 0.8683\n",
      "Epoch 106/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3695 - accuracy: 0.8449 - val_loss: 0.3260 - val_accuracy: 0.8706\n",
      "Epoch 107/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3680 - accuracy: 0.8454 - val_loss: 0.3242 - val_accuracy: 0.8699\n",
      "Epoch 108/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3676 - accuracy: 0.8462 - val_loss: 0.3234 - val_accuracy: 0.8709\n",
      "Epoch 109/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3641 - accuracy: 0.8469 - val_loss: 0.3224 - val_accuracy: 0.8715\n",
      "Epoch 110/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3652 - accuracy: 0.8464 - val_loss: 0.3212 - val_accuracy: 0.8721\n",
      "Epoch 111/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3628 - accuracy: 0.8482 - val_loss: 0.3207 - val_accuracy: 0.8720\n",
      "Epoch 112/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3607 - accuracy: 0.8492 - val_loss: 0.3197 - val_accuracy: 0.8720\n",
      "Epoch 113/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3618 - accuracy: 0.8498 - val_loss: 0.3170 - val_accuracy: 0.8737\n",
      "Epoch 114/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3606 - accuracy: 0.8492 - val_loss: 0.3165 - val_accuracy: 0.8734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3598 - accuracy: 0.8502 - val_loss: 0.3160 - val_accuracy: 0.8747\n",
      "Epoch 116/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3584 - accuracy: 0.8496 - val_loss: 0.3152 - val_accuracy: 0.8740\n",
      "Epoch 117/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3555 - accuracy: 0.8516 - val_loss: 0.3139 - val_accuracy: 0.8745\n",
      "Epoch 118/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3553 - accuracy: 0.8508 - val_loss: 0.3128 - val_accuracy: 0.8749\n",
      "Epoch 119/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3527 - accuracy: 0.8545 - val_loss: 0.3111 - val_accuracy: 0.8761\n",
      "Epoch 120/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3523 - accuracy: 0.8527 - val_loss: 0.3101 - val_accuracy: 0.8756\n",
      "Epoch 121/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3517 - accuracy: 0.8533 - val_loss: 0.3095 - val_accuracy: 0.8770\n",
      "Epoch 122/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3523 - accuracy: 0.8522 - val_loss: 0.3095 - val_accuracy: 0.8775\n",
      "Epoch 123/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3523 - accuracy: 0.8525 - val_loss: 0.3073 - val_accuracy: 0.8768\n",
      "Epoch 124/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3496 - accuracy: 0.8533 - val_loss: 0.3064 - val_accuracy: 0.8776\n",
      "Epoch 125/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3489 - accuracy: 0.8550 - val_loss: 0.3053 - val_accuracy: 0.8784\n",
      "Epoch 126/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3454 - accuracy: 0.8553 - val_loss: 0.3045 - val_accuracy: 0.8783\n",
      "Epoch 127/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3467 - accuracy: 0.8555 - val_loss: 0.3039 - val_accuracy: 0.8791\n",
      "Epoch 128/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3452 - accuracy: 0.8570 - val_loss: 0.3025 - val_accuracy: 0.8791\n",
      "Epoch 129/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3443 - accuracy: 0.8575 - val_loss: 0.3028 - val_accuracy: 0.8800\n",
      "Epoch 130/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3422 - accuracy: 0.8578 - val_loss: 0.3015 - val_accuracy: 0.8792\n",
      "Epoch 131/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3420 - accuracy: 0.8575 - val_loss: 0.2995 - val_accuracy: 0.8800\n",
      "Epoch 132/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3434 - accuracy: 0.8558 - val_loss: 0.2987 - val_accuracy: 0.8813\n",
      "Epoch 133/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3407 - accuracy: 0.8583 - val_loss: 0.2981 - val_accuracy: 0.8810\n",
      "Epoch 134/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3410 - accuracy: 0.8571 - val_loss: 0.2977 - val_accuracy: 0.8815\n",
      "Epoch 135/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3385 - accuracy: 0.8588 - val_loss: 0.2964 - val_accuracy: 0.8817\n",
      "Epoch 136/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3373 - accuracy: 0.8595 - val_loss: 0.2953 - val_accuracy: 0.8828\n",
      "Epoch 137/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3373 - accuracy: 0.8606 - val_loss: 0.2943 - val_accuracy: 0.8830\n",
      "Epoch 138/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3376 - accuracy: 0.8595 - val_loss: 0.2934 - val_accuracy: 0.8831\n",
      "Epoch 139/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3375 - accuracy: 0.8601 - val_loss: 0.2932 - val_accuracy: 0.8831\n",
      "Epoch 140/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3326 - accuracy: 0.8618 - val_loss: 0.2919 - val_accuracy: 0.8838\n",
      "Epoch 141/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3321 - accuracy: 0.8610 - val_loss: 0.2905 - val_accuracy: 0.8844\n",
      "Epoch 142/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3331 - accuracy: 0.8614 - val_loss: 0.2908 - val_accuracy: 0.8839\n",
      "Epoch 143/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3321 - accuracy: 0.8634 - val_loss: 0.2896 - val_accuracy: 0.8842\n",
      "Epoch 144/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3310 - accuracy: 0.8637 - val_loss: 0.2891 - val_accuracy: 0.8852\n",
      "Epoch 145/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3297 - accuracy: 0.8630 - val_loss: 0.2881 - val_accuracy: 0.8861\n",
      "Epoch 146/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3291 - accuracy: 0.8633 - val_loss: 0.2874 - val_accuracy: 0.8866\n",
      "Epoch 147/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3283 - accuracy: 0.8632 - val_loss: 0.2860 - val_accuracy: 0.8844\n",
      "Epoch 148/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3281 - accuracy: 0.8630 - val_loss: 0.2860 - val_accuracy: 0.8859\n",
      "Epoch 149/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3279 - accuracy: 0.8645 - val_loss: 0.2859 - val_accuracy: 0.8854\n",
      "Epoch 150/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3267 - accuracy: 0.8641 - val_loss: 0.2851 - val_accuracy: 0.8867\n",
      "Epoch 151/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3254 - accuracy: 0.8658 - val_loss: 0.2854 - val_accuracy: 0.8871\n",
      "Epoch 152/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3245 - accuracy: 0.8659 - val_loss: 0.2831 - val_accuracy: 0.8888\n",
      "Epoch 153/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3250 - accuracy: 0.8657 - val_loss: 0.2829 - val_accuracy: 0.8879\n",
      "Epoch 154/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3225 - accuracy: 0.8664 - val_loss: 0.2820 - val_accuracy: 0.8898\n",
      "Epoch 155/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3244 - accuracy: 0.8655 - val_loss: 0.2815 - val_accuracy: 0.8894\n",
      "Epoch 156/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3230 - accuracy: 0.8664 - val_loss: 0.2809 - val_accuracy: 0.8888\n",
      "Epoch 157/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3194 - accuracy: 0.8675 - val_loss: 0.2805 - val_accuracy: 0.8899\n",
      "Epoch 158/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3182 - accuracy: 0.8679 - val_loss: 0.2792 - val_accuracy: 0.8897\n",
      "Epoch 159/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3201 - accuracy: 0.8677 - val_loss: 0.2780 - val_accuracy: 0.8895\n",
      "Epoch 160/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3171 - accuracy: 0.8692 - val_loss: 0.2776 - val_accuracy: 0.8907\n",
      "Epoch 161/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3158 - accuracy: 0.8689 - val_loss: 0.2772 - val_accuracy: 0.8912\n",
      "Epoch 162/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3175 - accuracy: 0.8692 - val_loss: 0.2760 - val_accuracy: 0.8904\n",
      "Epoch 163/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3179 - accuracy: 0.8686 - val_loss: 0.2760 - val_accuracy: 0.8907\n",
      "Epoch 164/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3163 - accuracy: 0.8695 - val_loss: 0.2760 - val_accuracy: 0.8916\n",
      "Epoch 165/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3156 - accuracy: 0.8699 - val_loss: 0.2748 - val_accuracy: 0.8926\n",
      "Epoch 166/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3149 - accuracy: 0.8692 - val_loss: 0.2739 - val_accuracy: 0.8924\n",
      "Epoch 167/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3133 - accuracy: 0.8713 - val_loss: 0.2731 - val_accuracy: 0.8929\n",
      "Epoch 168/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3121 - accuracy: 0.8703 - val_loss: 0.2731 - val_accuracy: 0.8920\n",
      "Epoch 169/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3117 - accuracy: 0.8704 - val_loss: 0.2720 - val_accuracy: 0.8926\n",
      "Epoch 170/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3120 - accuracy: 0.8718 - val_loss: 0.2716 - val_accuracy: 0.8934\n",
      "Epoch 171/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3094 - accuracy: 0.8724 - val_loss: 0.2712 - val_accuracy: 0.8938\n",
      "Epoch 172/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3103 - accuracy: 0.8722 - val_loss: 0.2715 - val_accuracy: 0.8939\n",
      "Epoch 173/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3086 - accuracy: 0.8721 - val_loss: 0.2710 - val_accuracy: 0.8941\n",
      "Epoch 174/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3093 - accuracy: 0.8730 - val_loss: 0.2694 - val_accuracy: 0.8952\n",
      "Epoch 175/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3075 - accuracy: 0.8727 - val_loss: 0.2693 - val_accuracy: 0.8942\n",
      "Epoch 176/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3080 - accuracy: 0.8726 - val_loss: 0.2687 - val_accuracy: 0.8946\n",
      "Epoch 177/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3049 - accuracy: 0.8745 - val_loss: 0.2682 - val_accuracy: 0.8944\n",
      "Epoch 178/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3073 - accuracy: 0.8728 - val_loss: 0.2677 - val_accuracy: 0.8961\n",
      "Epoch 179/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3071 - accuracy: 0.8723 - val_loss: 0.2676 - val_accuracy: 0.8963\n",
      "Epoch 180/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3048 - accuracy: 0.8748 - val_loss: 0.2665 - val_accuracy: 0.8949\n",
      "Epoch 181/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3047 - accuracy: 0.8745 - val_loss: 0.2656 - val_accuracy: 0.8960\n",
      "Epoch 182/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3044 - accuracy: 0.8746 - val_loss: 0.2662 - val_accuracy: 0.8960\n",
      "Epoch 183/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3036 - accuracy: 0.8738 - val_loss: 0.2654 - val_accuracy: 0.8953\n",
      "Epoch 184/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3032 - accuracy: 0.8749 - val_loss: 0.2648 - val_accuracy: 0.8966\n",
      "Epoch 185/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3003 - accuracy: 0.8769 - val_loss: 0.2638 - val_accuracy: 0.8955\n",
      "Epoch 186/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3024 - accuracy: 0.8753 - val_loss: 0.2631 - val_accuracy: 0.8971\n",
      "Epoch 187/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.3004 - accuracy: 0.8762 - val_loss: 0.2624 - val_accuracy: 0.8981\n",
      "Epoch 188/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2999 - accuracy: 0.8762 - val_loss: 0.2625 - val_accuracy: 0.8968\n",
      "Epoch 189/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2989 - accuracy: 0.8754 - val_loss: 0.2622 - val_accuracy: 0.8977\n",
      "Epoch 190/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2987 - accuracy: 0.8776 - val_loss: 0.2614 - val_accuracy: 0.8984\n",
      "Epoch 191/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2982 - accuracy: 0.8764 - val_loss: 0.2605 - val_accuracy: 0.8993\n",
      "Epoch 192/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2997 - accuracy: 0.8763 - val_loss: 0.2600 - val_accuracy: 0.8991\n",
      "Epoch 193/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2986 - accuracy: 0.8768 - val_loss: 0.2603 - val_accuracy: 0.8986\n",
      "Epoch 194/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2983 - accuracy: 0.8773 - val_loss: 0.2594 - val_accuracy: 0.8989\n",
      "Epoch 195/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2951 - accuracy: 0.8782 - val_loss: 0.2583 - val_accuracy: 0.8992\n",
      "Epoch 196/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2955 - accuracy: 0.8782 - val_loss: 0.2585 - val_accuracy: 0.8989\n",
      "Epoch 197/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2946 - accuracy: 0.8794 - val_loss: 0.2579 - val_accuracy: 0.8993\n",
      "Epoch 198/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2945 - accuracy: 0.8783 - val_loss: 0.2573 - val_accuracy: 0.9013\n",
      "Epoch 199/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2936 - accuracy: 0.8792 - val_loss: 0.2574 - val_accuracy: 0.9002\n",
      "Epoch 200/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2939 - accuracy: 0.8777 - val_loss: 0.2565 - val_accuracy: 0.9013\n",
      "Epoch 201/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2941 - accuracy: 0.8793 - val_loss: 0.2563 - val_accuracy: 0.9007\n",
      "Epoch 202/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2911 - accuracy: 0.8802 - val_loss: 0.2557 - val_accuracy: 0.9017\n",
      "Epoch 203/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2912 - accuracy: 0.8793 - val_loss: 0.2546 - val_accuracy: 0.9029\n",
      "Epoch 204/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2903 - accuracy: 0.8804 - val_loss: 0.2545 - val_accuracy: 0.9011\n",
      "Epoch 205/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2910 - accuracy: 0.8798 - val_loss: 0.2541 - val_accuracy: 0.9025\n",
      "Epoch 206/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2890 - accuracy: 0.8800 - val_loss: 0.2530 - val_accuracy: 0.9037\n",
      "Epoch 207/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2899 - accuracy: 0.8807 - val_loss: 0.2531 - val_accuracy: 0.9025\n",
      "Epoch 208/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2892 - accuracy: 0.8806 - val_loss: 0.2532 - val_accuracy: 0.9028\n",
      "Epoch 209/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2882 - accuracy: 0.8810 - val_loss: 0.2522 - val_accuracy: 0.9020\n",
      "Epoch 210/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2870 - accuracy: 0.8817 - val_loss: 0.2528 - val_accuracy: 0.9011\n",
      "Epoch 211/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2883 - accuracy: 0.8814 - val_loss: 0.2514 - val_accuracy: 0.9023\n",
      "Epoch 212/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2869 - accuracy: 0.8820 - val_loss: 0.2510 - val_accuracy: 0.9041\n",
      "Epoch 213/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2881 - accuracy: 0.8816 - val_loss: 0.2516 - val_accuracy: 0.9030\n",
      "Epoch 214/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2864 - accuracy: 0.8833 - val_loss: 0.2512 - val_accuracy: 0.9028\n",
      "Epoch 215/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2844 - accuracy: 0.8834 - val_loss: 0.2509 - val_accuracy: 0.9032\n",
      "Epoch 216/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2844 - accuracy: 0.8830 - val_loss: 0.2497 - val_accuracy: 0.9041\n",
      "Epoch 217/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2835 - accuracy: 0.8829 - val_loss: 0.2494 - val_accuracy: 0.9042\n",
      "Epoch 218/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2846 - accuracy: 0.8838 - val_loss: 0.2489 - val_accuracy: 0.9054\n",
      "Epoch 219/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2839 - accuracy: 0.8821 - val_loss: 0.2482 - val_accuracy: 0.9047\n",
      "Epoch 220/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2835 - accuracy: 0.8835 - val_loss: 0.2479 - val_accuracy: 0.9040\n",
      "Epoch 221/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2825 - accuracy: 0.8831 - val_loss: 0.2482 - val_accuracy: 0.9035\n",
      "Epoch 222/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2830 - accuracy: 0.8839 - val_loss: 0.2476 - val_accuracy: 0.9052\n",
      "Epoch 223/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2817 - accuracy: 0.8841 - val_loss: 0.2463 - val_accuracy: 0.9059\n",
      "Epoch 224/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2820 - accuracy: 0.8842 - val_loss: 0.2465 - val_accuracy: 0.9049\n",
      "Epoch 225/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2810 - accuracy: 0.8839 - val_loss: 0.2462 - val_accuracy: 0.9065\n",
      "Epoch 226/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2789 - accuracy: 0.8845 - val_loss: 0.2459 - val_accuracy: 0.9035\n",
      "Epoch 227/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2800 - accuracy: 0.8848 - val_loss: 0.2455 - val_accuracy: 0.9049\n",
      "Epoch 228/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2793 - accuracy: 0.8846 - val_loss: 0.2454 - val_accuracy: 0.9052\n",
      "Epoch 229/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2786 - accuracy: 0.8853 - val_loss: 0.2445 - val_accuracy: 0.9063\n",
      "Epoch 230/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2788 - accuracy: 0.8849 - val_loss: 0.2441 - val_accuracy: 0.9068\n",
      "Epoch 231/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2795 - accuracy: 0.8848 - val_loss: 0.2444 - val_accuracy: 0.9046\n",
      "Epoch 232/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2780 - accuracy: 0.8862 - val_loss: 0.2433 - val_accuracy: 0.9054\n",
      "Epoch 233/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2761 - accuracy: 0.8872 - val_loss: 0.2431 - val_accuracy: 0.9052\n",
      "Epoch 234/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2776 - accuracy: 0.8862 - val_loss: 0.2432 - val_accuracy: 0.9047\n",
      "Epoch 235/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2778 - accuracy: 0.8856 - val_loss: 0.2426 - val_accuracy: 0.9059\n",
      "Epoch 236/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2748 - accuracy: 0.8874 - val_loss: 0.2422 - val_accuracy: 0.9047\n",
      "Epoch 237/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2753 - accuracy: 0.8863 - val_loss: 0.2422 - val_accuracy: 0.9055\n",
      "Epoch 238/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2747 - accuracy: 0.8870 - val_loss: 0.2413 - val_accuracy: 0.9058\n",
      "Epoch 239/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2746 - accuracy: 0.8878 - val_loss: 0.2413 - val_accuracy: 0.9060\n",
      "Epoch 240/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2734 - accuracy: 0.8866 - val_loss: 0.2409 - val_accuracy: 0.9058\n",
      "Epoch 241/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2712 - accuracy: 0.8894 - val_loss: 0.2400 - val_accuracy: 0.9056\n",
      "Epoch 242/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2730 - accuracy: 0.8887 - val_loss: 0.2399 - val_accuracy: 0.9071\n",
      "Epoch 243/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2731 - accuracy: 0.8875 - val_loss: 0.2399 - val_accuracy: 0.9057\n",
      "Epoch 244/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2740 - accuracy: 0.8872 - val_loss: 0.2397 - val_accuracy: 0.9065\n",
      "Epoch 245/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2712 - accuracy: 0.8880 - val_loss: 0.2391 - val_accuracy: 0.9057\n",
      "Epoch 246/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2704 - accuracy: 0.8883 - val_loss: 0.2387 - val_accuracy: 0.9066\n",
      "Epoch 247/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2723 - accuracy: 0.8875 - val_loss: 0.2387 - val_accuracy: 0.9061\n",
      "Epoch 248/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2703 - accuracy: 0.8887 - val_loss: 0.2383 - val_accuracy: 0.9079\n",
      "Epoch 249/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2702 - accuracy: 0.8898 - val_loss: 0.2375 - val_accuracy: 0.9071\n",
      "Epoch 250/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2694 - accuracy: 0.8892 - val_loss: 0.2377 - val_accuracy: 0.9076\n",
      "Epoch 251/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2704 - accuracy: 0.8883 - val_loss: 0.2378 - val_accuracy: 0.9057\n",
      "Epoch 252/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2705 - accuracy: 0.8898 - val_loss: 0.2372 - val_accuracy: 0.9058\n",
      "Epoch 253/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2685 - accuracy: 0.8901 - val_loss: 0.2363 - val_accuracy: 0.9082\n",
      "Epoch 254/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2677 - accuracy: 0.8913 - val_loss: 0.2360 - val_accuracy: 0.9069\n",
      "Epoch 255/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2677 - accuracy: 0.8901 - val_loss: 0.2356 - val_accuracy: 0.9072\n",
      "Epoch 256/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2665 - accuracy: 0.8910 - val_loss: 0.2355 - val_accuracy: 0.9076\n",
      "Epoch 257/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2671 - accuracy: 0.8898 - val_loss: 0.2353 - val_accuracy: 0.9079\n",
      "Epoch 258/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2653 - accuracy: 0.8912 - val_loss: 0.2348 - val_accuracy: 0.9075\n",
      "Epoch 259/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2667 - accuracy: 0.8910 - val_loss: 0.2347 - val_accuracy: 0.9078\n",
      "Epoch 260/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2655 - accuracy: 0.8914 - val_loss: 0.2339 - val_accuracy: 0.9094\n",
      "Epoch 261/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2646 - accuracy: 0.8904 - val_loss: 0.2345 - val_accuracy: 0.9082\n",
      "Epoch 262/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2646 - accuracy: 0.8904 - val_loss: 0.2342 - val_accuracy: 0.9084\n",
      "Epoch 263/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2658 - accuracy: 0.8901 - val_loss: 0.2334 - val_accuracy: 0.9099\n",
      "Epoch 264/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2654 - accuracy: 0.8908 - val_loss: 0.2334 - val_accuracy: 0.9081\n",
      "Epoch 265/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2638 - accuracy: 0.8921 - val_loss: 0.2329 - val_accuracy: 0.9096\n",
      "Epoch 266/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2637 - accuracy: 0.8914 - val_loss: 0.2325 - val_accuracy: 0.9082\n",
      "Epoch 267/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2632 - accuracy: 0.8922 - val_loss: 0.2319 - val_accuracy: 0.9095\n",
      "Epoch 268/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2626 - accuracy: 0.8924 - val_loss: 0.2321 - val_accuracy: 0.9106\n",
      "Epoch 269/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2632 - accuracy: 0.8929 - val_loss: 0.2313 - val_accuracy: 0.9113\n",
      "Epoch 270/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2621 - accuracy: 0.8931 - val_loss: 0.2307 - val_accuracy: 0.9117\n",
      "Epoch 271/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2631 - accuracy: 0.8915 - val_loss: 0.2304 - val_accuracy: 0.9108\n",
      "Epoch 272/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2625 - accuracy: 0.8921 - val_loss: 0.2305 - val_accuracy: 0.9113\n",
      "Epoch 273/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2613 - accuracy: 0.8921 - val_loss: 0.2303 - val_accuracy: 0.9112\n",
      "Epoch 274/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2624 - accuracy: 0.8913 - val_loss: 0.2301 - val_accuracy: 0.9112\n",
      "Epoch 275/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2604 - accuracy: 0.8932 - val_loss: 0.2299 - val_accuracy: 0.9113\n",
      "Epoch 276/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2595 - accuracy: 0.8935 - val_loss: 0.2294 - val_accuracy: 0.9108\n",
      "Epoch 277/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2601 - accuracy: 0.8932 - val_loss: 0.2288 - val_accuracy: 0.9119\n",
      "Epoch 278/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2593 - accuracy: 0.8935 - val_loss: 0.2293 - val_accuracy: 0.9104\n",
      "Epoch 279/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2609 - accuracy: 0.8937 - val_loss: 0.2291 - val_accuracy: 0.9111\n",
      "Epoch 280/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2587 - accuracy: 0.8942 - val_loss: 0.2287 - val_accuracy: 0.9111\n",
      "Epoch 281/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2584 - accuracy: 0.8940 - val_loss: 0.2278 - val_accuracy: 0.9134\n",
      "Epoch 282/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2564 - accuracy: 0.8942 - val_loss: 0.2274 - val_accuracy: 0.9129\n",
      "Epoch 283/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2564 - accuracy: 0.8957 - val_loss: 0.2277 - val_accuracy: 0.9116\n",
      "Epoch 284/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2572 - accuracy: 0.8946 - val_loss: 0.2267 - val_accuracy: 0.9125\n",
      "Epoch 285/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2555 - accuracy: 0.8947 - val_loss: 0.2272 - val_accuracy: 0.9114\n",
      "Epoch 286/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2558 - accuracy: 0.8946 - val_loss: 0.2267 - val_accuracy: 0.9122\n",
      "Epoch 287/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2548 - accuracy: 0.8956 - val_loss: 0.2263 - val_accuracy: 0.9125\n",
      "Epoch 288/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2549 - accuracy: 0.8955 - val_loss: 0.2263 - val_accuracy: 0.9113\n",
      "Epoch 289/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2564 - accuracy: 0.8949 - val_loss: 0.2263 - val_accuracy: 0.9129\n",
      "Epoch 290/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2550 - accuracy: 0.8950 - val_loss: 0.2252 - val_accuracy: 0.9129\n",
      "Epoch 291/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2536 - accuracy: 0.8962 - val_loss: 0.2255 - val_accuracy: 0.9111\n",
      "Epoch 292/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2544 - accuracy: 0.8957 - val_loss: 0.2259 - val_accuracy: 0.9115\n",
      "Epoch 293/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2539 - accuracy: 0.8957 - val_loss: 0.2249 - val_accuracy: 0.9126\n",
      "Epoch 294/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2533 - accuracy: 0.8950 - val_loss: 0.2246 - val_accuracy: 0.9131\n",
      "Epoch 295/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2542 - accuracy: 0.8962 - val_loss: 0.2244 - val_accuracy: 0.9131\n",
      "Epoch 296/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2531 - accuracy: 0.8970 - val_loss: 0.2241 - val_accuracy: 0.9137\n",
      "Epoch 297/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2518 - accuracy: 0.8966 - val_loss: 0.2244 - val_accuracy: 0.9125\n",
      "Epoch 298/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2534 - accuracy: 0.8965 - val_loss: 0.2237 - val_accuracy: 0.9134\n",
      "Epoch 299/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2497 - accuracy: 0.8970 - val_loss: 0.2230 - val_accuracy: 0.9132\n",
      "Epoch 300/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2507 - accuracy: 0.8980 - val_loss: 0.2230 - val_accuracy: 0.9123\n",
      "Epoch 301/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2522 - accuracy: 0.8956 - val_loss: 0.2228 - val_accuracy: 0.9141\n",
      "Epoch 302/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2498 - accuracy: 0.8966 - val_loss: 0.2230 - val_accuracy: 0.9113\n",
      "Epoch 303/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2501 - accuracy: 0.8968 - val_loss: 0.2221 - val_accuracy: 0.9131\n",
      "Epoch 304/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2473 - accuracy: 0.8989 - val_loss: 0.2219 - val_accuracy: 0.9139\n",
      "Epoch 305/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2503 - accuracy: 0.8981 - val_loss: 0.2210 - val_accuracy: 0.9136\n",
      "Epoch 306/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2478 - accuracy: 0.8984 - val_loss: 0.2213 - val_accuracy: 0.9136\n",
      "Epoch 307/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2493 - accuracy: 0.8979 - val_loss: 0.2210 - val_accuracy: 0.9126\n",
      "Epoch 308/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2490 - accuracy: 0.8983 - val_loss: 0.2211 - val_accuracy: 0.9123\n",
      "Epoch 309/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2469 - accuracy: 0.8987 - val_loss: 0.2204 - val_accuracy: 0.9134\n",
      "Epoch 310/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2465 - accuracy: 0.8992 - val_loss: 0.2201 - val_accuracy: 0.9142\n",
      "Epoch 311/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2485 - accuracy: 0.8983 - val_loss: 0.2198 - val_accuracy: 0.9149\n",
      "Epoch 312/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2460 - accuracy: 0.8997 - val_loss: 0.2195 - val_accuracy: 0.9147\n",
      "Epoch 313/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2466 - accuracy: 0.8992 - val_loss: 0.2199 - val_accuracy: 0.9138\n",
      "Epoch 314/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2480 - accuracy: 0.8977 - val_loss: 0.2195 - val_accuracy: 0.9148\n",
      "Epoch 315/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2467 - accuracy: 0.8973 - val_loss: 0.2193 - val_accuracy: 0.9135\n",
      "Epoch 316/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2452 - accuracy: 0.9005 - val_loss: 0.2190 - val_accuracy: 0.9142\n",
      "Epoch 317/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2441 - accuracy: 0.9011 - val_loss: 0.2187 - val_accuracy: 0.9134\n",
      "Epoch 318/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2454 - accuracy: 0.8990 - val_loss: 0.2186 - val_accuracy: 0.9137\n",
      "Epoch 319/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2451 - accuracy: 0.8997 - val_loss: 0.2181 - val_accuracy: 0.9140\n",
      "Epoch 320/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2442 - accuracy: 0.8999 - val_loss: 0.2181 - val_accuracy: 0.9134\n",
      "Epoch 321/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2436 - accuracy: 0.9010 - val_loss: 0.2173 - val_accuracy: 0.9160\n",
      "Epoch 322/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2434 - accuracy: 0.8999 - val_loss: 0.2177 - val_accuracy: 0.9146\n",
      "Epoch 323/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2429 - accuracy: 0.9002 - val_loss: 0.2169 - val_accuracy: 0.9140\n",
      "Epoch 324/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2437 - accuracy: 0.8988 - val_loss: 0.2174 - val_accuracy: 0.9144\n",
      "Epoch 325/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2429 - accuracy: 0.9012 - val_loss: 0.2164 - val_accuracy: 0.9148\n",
      "Epoch 326/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2424 - accuracy: 0.9003 - val_loss: 0.2169 - val_accuracy: 0.9139\n",
      "Epoch 327/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2425 - accuracy: 0.9011 - val_loss: 0.2155 - val_accuracy: 0.9156\n",
      "Epoch 328/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2431 - accuracy: 0.9006 - val_loss: 0.2156 - val_accuracy: 0.9156\n",
      "Epoch 329/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2423 - accuracy: 0.9011 - val_loss: 0.2158 - val_accuracy: 0.9147\n",
      "Epoch 330/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2397 - accuracy: 0.9023 - val_loss: 0.2154 - val_accuracy: 0.9156\n",
      "Epoch 331/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2403 - accuracy: 0.9015 - val_loss: 0.2149 - val_accuracy: 0.9156\n",
      "Epoch 332/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2402 - accuracy: 0.9013 - val_loss: 0.2145 - val_accuracy: 0.9141\n",
      "Epoch 333/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2397 - accuracy: 0.9012 - val_loss: 0.2149 - val_accuracy: 0.9156\n",
      "Epoch 334/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2411 - accuracy: 0.9015 - val_loss: 0.2143 - val_accuracy: 0.9161\n",
      "Epoch 335/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2401 - accuracy: 0.9020 - val_loss: 0.2139 - val_accuracy: 0.9159\n",
      "Epoch 336/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2391 - accuracy: 0.9022 - val_loss: 0.2140 - val_accuracy: 0.9161\n",
      "Epoch 337/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2402 - accuracy: 0.8998 - val_loss: 0.2141 - val_accuracy: 0.9151\n",
      "Epoch 338/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2380 - accuracy: 0.9023 - val_loss: 0.2136 - val_accuracy: 0.9157\n",
      "Epoch 339/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2386 - accuracy: 0.9023 - val_loss: 0.2135 - val_accuracy: 0.9167\n",
      "Epoch 340/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2380 - accuracy: 0.9025 - val_loss: 0.2127 - val_accuracy: 0.9159\n",
      "Epoch 341/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2390 - accuracy: 0.9024 - val_loss: 0.2127 - val_accuracy: 0.9170\n",
      "Epoch 342/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2379 - accuracy: 0.9024 - val_loss: 0.2128 - val_accuracy: 0.9164\n",
      "Epoch 343/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2374 - accuracy: 0.9029 - val_loss: 0.2128 - val_accuracy: 0.9152\n",
      "Epoch 344/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2374 - accuracy: 0.9016 - val_loss: 0.2123 - val_accuracy: 0.9158\n",
      "Epoch 345/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2370 - accuracy: 0.9027 - val_loss: 0.2119 - val_accuracy: 0.9170\n",
      "Epoch 346/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2360 - accuracy: 0.9043 - val_loss: 0.2121 - val_accuracy: 0.9166\n",
      "Epoch 347/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2369 - accuracy: 0.9023 - val_loss: 0.2111 - val_accuracy: 0.9169\n",
      "Epoch 348/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2355 - accuracy: 0.9039 - val_loss: 0.2110 - val_accuracy: 0.9164\n",
      "Epoch 349/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2364 - accuracy: 0.9028 - val_loss: 0.2108 - val_accuracy: 0.9156\n",
      "Epoch 350/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2345 - accuracy: 0.9038 - val_loss: 0.2110 - val_accuracy: 0.9161\n",
      "Epoch 351/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2350 - accuracy: 0.9037 - val_loss: 0.2105 - val_accuracy: 0.9159\n",
      "Epoch 352/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2366 - accuracy: 0.9034 - val_loss: 0.2107 - val_accuracy: 0.9170\n",
      "Epoch 353/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2340 - accuracy: 0.9046 - val_loss: 0.2104 - val_accuracy: 0.9166\n",
      "Epoch 354/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2342 - accuracy: 0.9039 - val_loss: 0.2093 - val_accuracy: 0.9166\n",
      "Epoch 355/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2326 - accuracy: 0.9046 - val_loss: 0.2093 - val_accuracy: 0.9165\n",
      "Epoch 356/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2343 - accuracy: 0.9042 - val_loss: 0.2093 - val_accuracy: 0.9176\n",
      "Epoch 357/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2336 - accuracy: 0.9045 - val_loss: 0.2091 - val_accuracy: 0.9179\n",
      "Epoch 358/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2331 - accuracy: 0.9045 - val_loss: 0.2084 - val_accuracy: 0.9178\n",
      "Epoch 359/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2356 - accuracy: 0.9045 - val_loss: 0.2087 - val_accuracy: 0.9185\n",
      "Epoch 360/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2313 - accuracy: 0.9054 - val_loss: 0.2082 - val_accuracy: 0.9178\n",
      "Epoch 361/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2341 - accuracy: 0.9040 - val_loss: 0.2083 - val_accuracy: 0.9175\n",
      "Epoch 362/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2309 - accuracy: 0.9053 - val_loss: 0.2082 - val_accuracy: 0.9177\n",
      "Epoch 363/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2323 - accuracy: 0.9039 - val_loss: 0.2077 - val_accuracy: 0.9175\n",
      "Epoch 364/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2321 - accuracy: 0.9050 - val_loss: 0.2073 - val_accuracy: 0.9188\n",
      "Epoch 365/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2318 - accuracy: 0.9043 - val_loss: 0.2074 - val_accuracy: 0.9184\n",
      "Epoch 366/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2303 - accuracy: 0.9054 - val_loss: 0.2073 - val_accuracy: 0.9186\n",
      "Epoch 367/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2295 - accuracy: 0.9049 - val_loss: 0.2070 - val_accuracy: 0.9186\n",
      "Epoch 368/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2296 - accuracy: 0.9064 - val_loss: 0.2070 - val_accuracy: 0.9182\n",
      "Epoch 369/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2303 - accuracy: 0.9068 - val_loss: 0.2067 - val_accuracy: 0.9178\n",
      "Epoch 370/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2302 - accuracy: 0.9056 - val_loss: 0.2066 - val_accuracy: 0.9185\n",
      "Epoch 371/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2296 - accuracy: 0.9055 - val_loss: 0.2068 - val_accuracy: 0.9180\n",
      "Epoch 372/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2288 - accuracy: 0.9051 - val_loss: 0.2058 - val_accuracy: 0.9186\n",
      "Epoch 373/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2307 - accuracy: 0.9044 - val_loss: 0.2061 - val_accuracy: 0.9189\n",
      "Epoch 374/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2301 - accuracy: 0.9055 - val_loss: 0.2056 - val_accuracy: 0.9179\n",
      "Epoch 375/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2280 - accuracy: 0.9064 - val_loss: 0.2061 - val_accuracy: 0.9178\n",
      "Epoch 376/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2292 - accuracy: 0.9060 - val_loss: 0.2050 - val_accuracy: 0.9196\n",
      "Epoch 377/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2284 - accuracy: 0.9073 - val_loss: 0.2046 - val_accuracy: 0.9197\n",
      "Epoch 378/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2265 - accuracy: 0.9075 - val_loss: 0.2049 - val_accuracy: 0.9187\n",
      "Epoch 379/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2276 - accuracy: 0.9062 - val_loss: 0.2049 - val_accuracy: 0.9194\n",
      "Epoch 380/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2283 - accuracy: 0.9057 - val_loss: 0.2049 - val_accuracy: 0.9191\n",
      "Epoch 381/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2270 - accuracy: 0.9066 - val_loss: 0.2042 - val_accuracy: 0.9185\n",
      "Epoch 382/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2278 - accuracy: 0.9066 - val_loss: 0.2045 - val_accuracy: 0.9190\n",
      "Epoch 383/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2278 - accuracy: 0.9054 - val_loss: 0.2042 - val_accuracy: 0.9194\n",
      "Epoch 384/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2267 - accuracy: 0.9074 - val_loss: 0.2037 - val_accuracy: 0.9188\n",
      "Epoch 385/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2268 - accuracy: 0.9075 - val_loss: 0.2038 - val_accuracy: 0.9200\n",
      "Epoch 386/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2267 - accuracy: 0.9075 - val_loss: 0.2036 - val_accuracy: 0.9193\n",
      "Epoch 387/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2255 - accuracy: 0.9082 - val_loss: 0.2032 - val_accuracy: 0.9203\n",
      "Epoch 388/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2251 - accuracy: 0.9076 - val_loss: 0.2032 - val_accuracy: 0.9208\n",
      "Epoch 389/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2269 - accuracy: 0.9066 - val_loss: 0.2019 - val_accuracy: 0.9204\n",
      "Epoch 390/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2256 - accuracy: 0.9074 - val_loss: 0.2020 - val_accuracy: 0.9205\n",
      "Epoch 391/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2246 - accuracy: 0.9077 - val_loss: 0.2021 - val_accuracy: 0.9205\n",
      "Epoch 392/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2234 - accuracy: 0.9081 - val_loss: 0.2021 - val_accuracy: 0.9206\n",
      "Epoch 393/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2245 - accuracy: 0.9089 - val_loss: 0.2021 - val_accuracy: 0.9203\n",
      "Epoch 394/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2237 - accuracy: 0.9069 - val_loss: 0.2009 - val_accuracy: 0.9209\n",
      "Epoch 395/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2241 - accuracy: 0.9072 - val_loss: 0.2018 - val_accuracy: 0.9199\n",
      "Epoch 396/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2247 - accuracy: 0.9069 - val_loss: 0.2013 - val_accuracy: 0.9199\n",
      "Epoch 397/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2234 - accuracy: 0.9084 - val_loss: 0.2018 - val_accuracy: 0.9202\n",
      "Epoch 398/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2224 - accuracy: 0.9085 - val_loss: 0.2014 - val_accuracy: 0.9199\n",
      "Epoch 399/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2228 - accuracy: 0.9084 - val_loss: 0.2011 - val_accuracy: 0.9196\n",
      "Epoch 400/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2222 - accuracy: 0.9092 - val_loss: 0.2003 - val_accuracy: 0.9206\n",
      "Epoch 401/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2215 - accuracy: 0.9091 - val_loss: 0.2003 - val_accuracy: 0.9201\n",
      "Epoch 402/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2219 - accuracy: 0.9090 - val_loss: 0.2005 - val_accuracy: 0.9202\n",
      "Epoch 403/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2225 - accuracy: 0.9081 - val_loss: 0.2001 - val_accuracy: 0.9206\n",
      "Epoch 404/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2227 - accuracy: 0.9082 - val_loss: 0.1998 - val_accuracy: 0.9204\n",
      "Epoch 405/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2215 - accuracy: 0.9088 - val_loss: 0.1991 - val_accuracy: 0.9209\n",
      "Epoch 406/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2218 - accuracy: 0.9095 - val_loss: 0.1989 - val_accuracy: 0.9218\n",
      "Epoch 407/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2203 - accuracy: 0.9102 - val_loss: 0.1992 - val_accuracy: 0.9213\n",
      "Epoch 408/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2204 - accuracy: 0.9102 - val_loss: 0.1992 - val_accuracy: 0.9205\n",
      "Epoch 409/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2201 - accuracy: 0.9096 - val_loss: 0.1994 - val_accuracy: 0.9211\n",
      "Epoch 410/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2213 - accuracy: 0.9089 - val_loss: 0.1986 - val_accuracy: 0.9211\n",
      "Epoch 411/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2209 - accuracy: 0.9090 - val_loss: 0.1985 - val_accuracy: 0.9218\n",
      "Epoch 412/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2204 - accuracy: 0.9086 - val_loss: 0.1985 - val_accuracy: 0.9201\n",
      "Epoch 413/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2207 - accuracy: 0.9099 - val_loss: 0.1983 - val_accuracy: 0.9202\n",
      "Epoch 414/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2190 - accuracy: 0.9101 - val_loss: 0.1982 - val_accuracy: 0.9210\n",
      "Epoch 415/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2192 - accuracy: 0.9103 - val_loss: 0.1980 - val_accuracy: 0.9207\n",
      "Epoch 416/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2192 - accuracy: 0.9097 - val_loss: 0.1977 - val_accuracy: 0.9213\n",
      "Epoch 417/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2209 - accuracy: 0.9101 - val_loss: 0.1978 - val_accuracy: 0.9216\n",
      "Epoch 418/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2184 - accuracy: 0.9108 - val_loss: 0.1979 - val_accuracy: 0.9217\n",
      "Epoch 419/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.2199 - accuracy: 0.9101 - val_loss: 0.1975 - val_accuracy: 0.9217\n",
      "Epoch 420/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2172 - accuracy: 0.9103 - val_loss: 0.1972 - val_accuracy: 0.9217\n",
      "Epoch 421/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2180 - accuracy: 0.9108 - val_loss: 0.1974 - val_accuracy: 0.9218\n",
      "Epoch 422/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2157 - accuracy: 0.9116 - val_loss: 0.1965 - val_accuracy: 0.9219\n",
      "Epoch 423/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2179 - accuracy: 0.9104 - val_loss: 0.1969 - val_accuracy: 0.9222\n",
      "Epoch 424/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2167 - accuracy: 0.9116 - val_loss: 0.1968 - val_accuracy: 0.9218\n",
      "Epoch 425/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2172 - accuracy: 0.9111 - val_loss: 0.1964 - val_accuracy: 0.9218\n",
      "Epoch 426/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2166 - accuracy: 0.9113 - val_loss: 0.1961 - val_accuracy: 0.9222\n",
      "Epoch 427/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2164 - accuracy: 0.9112 - val_loss: 0.1964 - val_accuracy: 0.9228\n",
      "Epoch 428/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2161 - accuracy: 0.9112 - val_loss: 0.1951 - val_accuracy: 0.9224\n",
      "Epoch 429/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2144 - accuracy: 0.9121 - val_loss: 0.1953 - val_accuracy: 0.9214\n",
      "Epoch 430/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2163 - accuracy: 0.9117 - val_loss: 0.1954 - val_accuracy: 0.9227\n",
      "Epoch 431/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2152 - accuracy: 0.9118 - val_loss: 0.1953 - val_accuracy: 0.9218\n",
      "Epoch 432/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2144 - accuracy: 0.9114 - val_loss: 0.1950 - val_accuracy: 0.9229\n",
      "Epoch 433/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2148 - accuracy: 0.9127 - val_loss: 0.1950 - val_accuracy: 0.9224\n",
      "Epoch 434/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2159 - accuracy: 0.9101 - val_loss: 0.1948 - val_accuracy: 0.9227\n",
      "Epoch 435/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2151 - accuracy: 0.9107 - val_loss: 0.1950 - val_accuracy: 0.9219\n",
      "Epoch 436/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2140 - accuracy: 0.9131 - val_loss: 0.1945 - val_accuracy: 0.9229\n",
      "Epoch 437/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2142 - accuracy: 0.9111 - val_loss: 0.1944 - val_accuracy: 0.9230\n",
      "Epoch 438/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2160 - accuracy: 0.9122 - val_loss: 0.1945 - val_accuracy: 0.9235\n",
      "Epoch 439/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2129 - accuracy: 0.9128 - val_loss: 0.1944 - val_accuracy: 0.9229\n",
      "Epoch 440/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2121 - accuracy: 0.9138 - val_loss: 0.1944 - val_accuracy: 0.9226\n",
      "Epoch 441/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2141 - accuracy: 0.9123 - val_loss: 0.1939 - val_accuracy: 0.9231\n",
      "Epoch 442/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2140 - accuracy: 0.9120 - val_loss: 0.1933 - val_accuracy: 0.9231\n",
      "Epoch 443/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2129 - accuracy: 0.9124 - val_loss: 0.1932 - val_accuracy: 0.9235\n",
      "Epoch 444/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2125 - accuracy: 0.9127 - val_loss: 0.1932 - val_accuracy: 0.9234\n",
      "Epoch 445/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2135 - accuracy: 0.9123 - val_loss: 0.1927 - val_accuracy: 0.9240\n",
      "Epoch 446/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2122 - accuracy: 0.9129 - val_loss: 0.1925 - val_accuracy: 0.9236\n",
      "Epoch 447/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2118 - accuracy: 0.9131 - val_loss: 0.1926 - val_accuracy: 0.9229\n",
      "Epoch 448/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2112 - accuracy: 0.9135 - val_loss: 0.1927 - val_accuracy: 0.9224\n",
      "Epoch 449/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2122 - accuracy: 0.9140 - val_loss: 0.1928 - val_accuracy: 0.9237\n",
      "Epoch 450/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2121 - accuracy: 0.9128 - val_loss: 0.1922 - val_accuracy: 0.9248\n",
      "Epoch 451/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2102 - accuracy: 0.9144 - val_loss: 0.1930 - val_accuracy: 0.9237\n",
      "Epoch 452/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.2110 - accuracy: 0.9134 - val_loss: 0.1918 - val_accuracy: 0.9245\n",
      "Epoch 453/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.2100 - accuracy: 0.9136 - val_loss: 0.1917 - val_accuracy: 0.9242\n",
      "Epoch 454/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2110 - accuracy: 0.9133 - val_loss: 0.1915 - val_accuracy: 0.9244\n",
      "Epoch 455/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2094 - accuracy: 0.9141 - val_loss: 0.1910 - val_accuracy: 0.9244\n",
      "Epoch 456/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2105 - accuracy: 0.9130 - val_loss: 0.1912 - val_accuracy: 0.9236\n",
      "Epoch 457/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2105 - accuracy: 0.9134 - val_loss: 0.1911 - val_accuracy: 0.9252\n",
      "Epoch 458/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2103 - accuracy: 0.9132 - val_loss: 0.1910 - val_accuracy: 0.9232\n",
      "Epoch 459/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2107 - accuracy: 0.9136 - val_loss: 0.1915 - val_accuracy: 0.9251\n",
      "Epoch 460/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2101 - accuracy: 0.9140 - val_loss: 0.1907 - val_accuracy: 0.9250\n",
      "Epoch 461/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2080 - accuracy: 0.9152 - val_loss: 0.1907 - val_accuracy: 0.9249\n",
      "Epoch 462/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2079 - accuracy: 0.9147 - val_loss: 0.1910 - val_accuracy: 0.9256\n",
      "Epoch 463/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2093 - accuracy: 0.9142 - val_loss: 0.1905 - val_accuracy: 0.9251\n",
      "Epoch 464/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2081 - accuracy: 0.9139 - val_loss: 0.1903 - val_accuracy: 0.9250\n",
      "Epoch 465/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.2086 - accuracy: 0.9149 - val_loss: 0.1903 - val_accuracy: 0.9242\n",
      "Epoch 466/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2088 - accuracy: 0.9144 - val_loss: 0.1894 - val_accuracy: 0.9252\n",
      "Epoch 467/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.2077 - accuracy: 0.9153 - val_loss: 0.1896 - val_accuracy: 0.9259\n",
      "Epoch 468/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2082 - accuracy: 0.9149 - val_loss: 0.1896 - val_accuracy: 0.9255\n",
      "Epoch 469/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2071 - accuracy: 0.9149 - val_loss: 0.1891 - val_accuracy: 0.9243\n",
      "Epoch 470/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2061 - accuracy: 0.9159 - val_loss: 0.1889 - val_accuracy: 0.9259\n",
      "Epoch 471/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2083 - accuracy: 0.9139 - val_loss: 0.1892 - val_accuracy: 0.9256\n",
      "Epoch 472/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2075 - accuracy: 0.9150 - val_loss: 0.1888 - val_accuracy: 0.9258\n",
      "Epoch 473/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2060 - accuracy: 0.9157 - val_loss: 0.1889 - val_accuracy: 0.9257\n",
      "Epoch 474/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2065 - accuracy: 0.9143 - val_loss: 0.1888 - val_accuracy: 0.9259\n",
      "Epoch 475/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2073 - accuracy: 0.9152 - val_loss: 0.1882 - val_accuracy: 0.9260\n",
      "Epoch 476/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2059 - accuracy: 0.9154 - val_loss: 0.1880 - val_accuracy: 0.9255\n",
      "Epoch 477/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2057 - accuracy: 0.9153 - val_loss: 0.1886 - val_accuracy: 0.9263\n",
      "Epoch 478/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2073 - accuracy: 0.9149 - val_loss: 0.1878 - val_accuracy: 0.9261\n",
      "Epoch 479/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2052 - accuracy: 0.9164 - val_loss: 0.1880 - val_accuracy: 0.9255\n",
      "Epoch 480/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2047 - accuracy: 0.9155 - val_loss: 0.1876 - val_accuracy: 0.9263\n",
      "Epoch 481/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.2065 - accuracy: 0.9144 - val_loss: 0.1876 - val_accuracy: 0.9263\n",
      "Epoch 482/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2039 - accuracy: 0.9162 - val_loss: 0.1873 - val_accuracy: 0.9253\n",
      "Epoch 483/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2050 - accuracy: 0.9163 - val_loss: 0.1876 - val_accuracy: 0.9263\n",
      "Epoch 484/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2058 - accuracy: 0.9150 - val_loss: 0.1868 - val_accuracy: 0.9269\n",
      "Epoch 485/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2048 - accuracy: 0.9148 - val_loss: 0.1872 - val_accuracy: 0.9254\n",
      "Epoch 486/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.2040 - accuracy: 0.9162 - val_loss: 0.1871 - val_accuracy: 0.9267\n",
      "Epoch 487/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.2027 - accuracy: 0.9173 - val_loss: 0.1868 - val_accuracy: 0.9270\n",
      "Epoch 488/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2056 - accuracy: 0.9147 - val_loss: 0.1864 - val_accuracy: 0.9269\n",
      "Epoch 489/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2036 - accuracy: 0.9163 - val_loss: 0.1867 - val_accuracy: 0.9268\n",
      "Epoch 490/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2047 - accuracy: 0.9162 - val_loss: 0.1865 - val_accuracy: 0.9266\n",
      "Epoch 491/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2034 - accuracy: 0.9162 - val_loss: 0.1865 - val_accuracy: 0.9263\n",
      "Epoch 492/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2025 - accuracy: 0.9168 - val_loss: 0.1864 - val_accuracy: 0.9271\n",
      "Epoch 493/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2010 - accuracy: 0.9180 - val_loss: 0.1856 - val_accuracy: 0.9270\n",
      "Epoch 494/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2025 - accuracy: 0.9170 - val_loss: 0.1854 - val_accuracy: 0.9270\n",
      "Epoch 495/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2039 - accuracy: 0.9170 - val_loss: 0.1858 - val_accuracy: 0.9279\n",
      "Epoch 496/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2033 - accuracy: 0.9163 - val_loss: 0.1854 - val_accuracy: 0.9282\n",
      "Epoch 497/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2021 - accuracy: 0.9175 - val_loss: 0.1850 - val_accuracy: 0.9275\n",
      "Epoch 498/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2036 - accuracy: 0.9173 - val_loss: 0.1850 - val_accuracy: 0.9271\n",
      "Epoch 499/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.2014 - accuracy: 0.9177 - val_loss: 0.1846 - val_accuracy: 0.9269\n",
      "Epoch 500/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2016 - accuracy: 0.9173 - val_loss: 0.1850 - val_accuracy: 0.9275\n",
      "Epoch 501/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.2024 - accuracy: 0.9163 - val_loss: 0.1847 - val_accuracy: 0.9274\n",
      "Epoch 502/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.2013 - accuracy: 0.9170 - val_loss: 0.1847 - val_accuracy: 0.9272\n",
      "Epoch 503/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2016 - accuracy: 0.9173 - val_loss: 0.1848 - val_accuracy: 0.9279\n",
      "Epoch 504/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2006 - accuracy: 0.9173 - val_loss: 0.1847 - val_accuracy: 0.9278\n",
      "Epoch 505/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2021 - accuracy: 0.9168 - val_loss: 0.1839 - val_accuracy: 0.9281\n",
      "Epoch 506/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.2001 - accuracy: 0.9181 - val_loss: 0.1842 - val_accuracy: 0.9279\n",
      "Epoch 507/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 6s 9ms/step - loss: 0.2009 - accuracy: 0.9174 - val_loss: 0.1842 - val_accuracy: 0.9276\n",
      "Epoch 508/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2004 - accuracy: 0.9177 - val_loss: 0.1842 - val_accuracy: 0.9279\n",
      "Epoch 509/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2006 - accuracy: 0.9183 - val_loss: 0.1840 - val_accuracy: 0.9280\n",
      "Epoch 510/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1983 - accuracy: 0.9190 - val_loss: 0.1835 - val_accuracy: 0.9278\n",
      "Epoch 511/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1993 - accuracy: 0.9183 - val_loss: 0.1835 - val_accuracy: 0.9282\n",
      "Epoch 512/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2007 - accuracy: 0.9175 - val_loss: 0.1835 - val_accuracy: 0.9277\n",
      "Epoch 513/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2005 - accuracy: 0.9178 - val_loss: 0.1832 - val_accuracy: 0.9287\n",
      "Epoch 514/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1987 - accuracy: 0.9189 - val_loss: 0.1831 - val_accuracy: 0.9281\n",
      "Epoch 515/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1981 - accuracy: 0.9187 - val_loss: 0.1834 - val_accuracy: 0.9285\n",
      "Epoch 516/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1978 - accuracy: 0.9189 - val_loss: 0.1831 - val_accuracy: 0.9286\n",
      "Epoch 517/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.2006 - accuracy: 0.9169 - val_loss: 0.1831 - val_accuracy: 0.9276\n",
      "Epoch 518/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.2000 - accuracy: 0.9184 - val_loss: 0.1830 - val_accuracy: 0.9286\n",
      "Epoch 519/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1993 - accuracy: 0.9182 - val_loss: 0.1827 - val_accuracy: 0.9282\n",
      "Epoch 520/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1980 - accuracy: 0.9192 - val_loss: 0.1823 - val_accuracy: 0.9285\n",
      "Epoch 521/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1978 - accuracy: 0.9189 - val_loss: 0.1825 - val_accuracy: 0.9292\n",
      "Epoch 522/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1973 - accuracy: 0.9196 - val_loss: 0.1824 - val_accuracy: 0.9282\n",
      "Epoch 523/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1965 - accuracy: 0.9193 - val_loss: 0.1820 - val_accuracy: 0.9287\n",
      "Epoch 524/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1971 - accuracy: 0.9196 - val_loss: 0.1823 - val_accuracy: 0.9283\n",
      "Epoch 525/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1977 - accuracy: 0.9196 - val_loss: 0.1821 - val_accuracy: 0.9288\n",
      "Epoch 526/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1966 - accuracy: 0.9199 - val_loss: 0.1815 - val_accuracy: 0.9292\n",
      "Epoch 527/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1954 - accuracy: 0.9203 - val_loss: 0.1817 - val_accuracy: 0.9288\n",
      "Epoch 528/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1964 - accuracy: 0.9192 - val_loss: 0.1815 - val_accuracy: 0.9286\n",
      "Epoch 529/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1977 - accuracy: 0.9185 - val_loss: 0.1818 - val_accuracy: 0.9285\n",
      "Epoch 530/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1968 - accuracy: 0.9191 - val_loss: 0.1816 - val_accuracy: 0.9291\n",
      "Epoch 531/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1962 - accuracy: 0.9195 - val_loss: 0.1811 - val_accuracy: 0.9288\n",
      "Epoch 532/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1965 - accuracy: 0.9199 - val_loss: 0.1816 - val_accuracy: 0.9294\n",
      "Epoch 533/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1946 - accuracy: 0.9203 - val_loss: 0.1813 - val_accuracy: 0.9288\n",
      "Epoch 534/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1959 - accuracy: 0.9202 - val_loss: 0.1810 - val_accuracy: 0.9284\n",
      "Epoch 535/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1944 - accuracy: 0.9200 - val_loss: 0.1809 - val_accuracy: 0.9286\n",
      "Epoch 536/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1938 - accuracy: 0.9211 - val_loss: 0.1806 - val_accuracy: 0.9290\n",
      "Epoch 537/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1962 - accuracy: 0.9200 - val_loss: 0.1806 - val_accuracy: 0.9292\n",
      "Epoch 538/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1954 - accuracy: 0.9197 - val_loss: 0.1802 - val_accuracy: 0.9300\n",
      "Epoch 539/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1940 - accuracy: 0.9195 - val_loss: 0.1801 - val_accuracy: 0.9285\n",
      "Epoch 540/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1958 - accuracy: 0.9201 - val_loss: 0.1799 - val_accuracy: 0.9298\n",
      "Epoch 541/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1927 - accuracy: 0.9204 - val_loss: 0.1799 - val_accuracy: 0.9296\n",
      "Epoch 542/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1959 - accuracy: 0.9203 - val_loss: 0.1804 - val_accuracy: 0.9285\n",
      "Epoch 543/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1955 - accuracy: 0.9199 - val_loss: 0.1795 - val_accuracy: 0.9290\n",
      "Epoch 544/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1959 - accuracy: 0.9198 - val_loss: 0.1796 - val_accuracy: 0.9287\n",
      "Epoch 545/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1934 - accuracy: 0.9200 - val_loss: 0.1792 - val_accuracy: 0.9291\n",
      "Epoch 546/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1944 - accuracy: 0.9197 - val_loss: 0.1792 - val_accuracy: 0.9298\n",
      "Epoch 547/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1937 - accuracy: 0.9211 - val_loss: 0.1790 - val_accuracy: 0.9297\n",
      "Epoch 548/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1937 - accuracy: 0.9211 - val_loss: 0.1793 - val_accuracy: 0.9296\n",
      "Epoch 549/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1924 - accuracy: 0.9213 - val_loss: 0.1794 - val_accuracy: 0.9298\n",
      "Epoch 550/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1947 - accuracy: 0.9198 - val_loss: 0.1793 - val_accuracy: 0.9300\n",
      "Epoch 551/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1927 - accuracy: 0.9208 - val_loss: 0.1784 - val_accuracy: 0.9296\n",
      "Epoch 552/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1933 - accuracy: 0.9210 - val_loss: 0.1792 - val_accuracy: 0.9296\n",
      "Epoch 553/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1935 - accuracy: 0.9208 - val_loss: 0.1787 - val_accuracy: 0.9294\n",
      "Epoch 554/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1932 - accuracy: 0.9215 - val_loss: 0.1789 - val_accuracy: 0.9298\n",
      "Epoch 555/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1937 - accuracy: 0.9212 - val_loss: 0.1789 - val_accuracy: 0.9285\n",
      "Epoch 556/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1919 - accuracy: 0.9211 - val_loss: 0.1783 - val_accuracy: 0.9298\n",
      "Epoch 557/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1930 - accuracy: 0.9204 - val_loss: 0.1777 - val_accuracy: 0.9296\n",
      "Epoch 558/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1931 - accuracy: 0.9209 - val_loss: 0.1782 - val_accuracy: 0.9301\n",
      "Epoch 559/700\n",
      "704/704 [==============================] - 7s 10ms/step - loss: 0.1927 - accuracy: 0.9214 - val_loss: 0.1776 - val_accuracy: 0.9299\n",
      "Epoch 560/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1905 - accuracy: 0.9220 - val_loss: 0.1772 - val_accuracy: 0.9307\n",
      "Epoch 561/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1923 - accuracy: 0.9218 - val_loss: 0.1778 - val_accuracy: 0.9296\n",
      "Epoch 562/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1911 - accuracy: 0.9226 - val_loss: 0.1773 - val_accuracy: 0.9290\n",
      "Epoch 563/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1930 - accuracy: 0.9207 - val_loss: 0.1774 - val_accuracy: 0.9294\n",
      "Epoch 564/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1945 - accuracy: 0.9208 - val_loss: 0.1779 - val_accuracy: 0.9290\n",
      "Epoch 565/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1911 - accuracy: 0.9215 - val_loss: 0.1774 - val_accuracy: 0.9292\n",
      "Epoch 566/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1904 - accuracy: 0.9218 - val_loss: 0.1769 - val_accuracy: 0.9305\n",
      "Epoch 567/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1921 - accuracy: 0.9208 - val_loss: 0.1772 - val_accuracy: 0.9300\n",
      "Epoch 568/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1908 - accuracy: 0.9212 - val_loss: 0.1769 - val_accuracy: 0.9300\n",
      "Epoch 569/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1902 - accuracy: 0.9226 - val_loss: 0.1770 - val_accuracy: 0.9300\n",
      "Epoch 570/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1895 - accuracy: 0.9232 - val_loss: 0.1767 - val_accuracy: 0.9301\n",
      "Epoch 571/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1911 - accuracy: 0.9215 - val_loss: 0.1764 - val_accuracy: 0.9307\n",
      "Epoch 572/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1918 - accuracy: 0.9211 - val_loss: 0.1766 - val_accuracy: 0.9312\n",
      "Epoch 573/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1903 - accuracy: 0.9230 - val_loss: 0.1762 - val_accuracy: 0.9307\n",
      "Epoch 574/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1877 - accuracy: 0.9217 - val_loss: 0.1762 - val_accuracy: 0.9301\n",
      "Epoch 575/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1897 - accuracy: 0.9217 - val_loss: 0.1771 - val_accuracy: 0.9311\n",
      "Epoch 576/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1892 - accuracy: 0.9225 - val_loss: 0.1763 - val_accuracy: 0.9302\n",
      "Epoch 577/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1890 - accuracy: 0.9228 - val_loss: 0.1760 - val_accuracy: 0.9308\n",
      "Epoch 578/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1882 - accuracy: 0.9228 - val_loss: 0.1761 - val_accuracy: 0.9301\n",
      "Epoch 579/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1899 - accuracy: 0.9219 - val_loss: 0.1760 - val_accuracy: 0.9311\n",
      "Epoch 580/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1899 - accuracy: 0.9228 - val_loss: 0.1759 - val_accuracy: 0.9312\n",
      "Epoch 581/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1877 - accuracy: 0.9228 - val_loss: 0.1754 - val_accuracy: 0.9305\n",
      "Epoch 582/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1888 - accuracy: 0.9235 - val_loss: 0.1751 - val_accuracy: 0.9308\n",
      "Epoch 583/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1884 - accuracy: 0.9227 - val_loss: 0.1758 - val_accuracy: 0.9305\n",
      "Epoch 584/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1875 - accuracy: 0.9227 - val_loss: 0.1753 - val_accuracy: 0.9306\n",
      "Epoch 585/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1867 - accuracy: 0.9237 - val_loss: 0.1752 - val_accuracy: 0.9308\n",
      "Epoch 586/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1867 - accuracy: 0.9232 - val_loss: 0.1752 - val_accuracy: 0.9307\n",
      "Epoch 587/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1889 - accuracy: 0.9233 - val_loss: 0.1751 - val_accuracy: 0.9311\n",
      "Epoch 588/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1867 - accuracy: 0.9230 - val_loss: 0.1752 - val_accuracy: 0.9309\n",
      "Epoch 589/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1882 - accuracy: 0.9221 - val_loss: 0.1750 - val_accuracy: 0.9313\n",
      "Epoch 590/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1876 - accuracy: 0.9229 - val_loss: 0.1748 - val_accuracy: 0.9305\n",
      "Epoch 591/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1871 - accuracy: 0.9226 - val_loss: 0.1749 - val_accuracy: 0.9311\n",
      "Epoch 592/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1865 - accuracy: 0.9242 - val_loss: 0.1743 - val_accuracy: 0.9309\n",
      "Epoch 593/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1869 - accuracy: 0.9230 - val_loss: 0.1746 - val_accuracy: 0.9303\n",
      "Epoch 594/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1849 - accuracy: 0.9239 - val_loss: 0.1743 - val_accuracy: 0.9310\n",
      "Epoch 595/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1883 - accuracy: 0.9224 - val_loss: 0.1744 - val_accuracy: 0.9307\n",
      "Epoch 596/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1875 - accuracy: 0.9233 - val_loss: 0.1739 - val_accuracy: 0.9318\n",
      "Epoch 597/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1869 - accuracy: 0.9234 - val_loss: 0.1743 - val_accuracy: 0.9307\n",
      "Epoch 598/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1866 - accuracy: 0.9238 - val_loss: 0.1742 - val_accuracy: 0.9313\n",
      "Epoch 599/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1869 - accuracy: 0.9234 - val_loss: 0.1740 - val_accuracy: 0.9317\n",
      "Epoch 600/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1864 - accuracy: 0.9233 - val_loss: 0.1732 - val_accuracy: 0.9321\n",
      "Epoch 601/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1854 - accuracy: 0.9251 - val_loss: 0.1732 - val_accuracy: 0.9315\n",
      "Epoch 602/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1859 - accuracy: 0.9240 - val_loss: 0.1740 - val_accuracy: 0.9309\n",
      "Epoch 603/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1855 - accuracy: 0.9248 - val_loss: 0.1734 - val_accuracy: 0.9322\n",
      "Epoch 604/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1861 - accuracy: 0.9249 - val_loss: 0.1731 - val_accuracy: 0.9326\n",
      "Epoch 605/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1849 - accuracy: 0.9248 - val_loss: 0.1731 - val_accuracy: 0.9323\n",
      "Epoch 606/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1829 - accuracy: 0.9251 - val_loss: 0.1726 - val_accuracy: 0.9320\n",
      "Epoch 607/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1850 - accuracy: 0.9238 - val_loss: 0.1732 - val_accuracy: 0.9319\n",
      "Epoch 608/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1860 - accuracy: 0.9235 - val_loss: 0.1727 - val_accuracy: 0.9323\n",
      "Epoch 609/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1846 - accuracy: 0.9246 - val_loss: 0.1726 - val_accuracy: 0.9318\n",
      "Epoch 610/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1851 - accuracy: 0.9236 - val_loss: 0.1728 - val_accuracy: 0.9322\n",
      "Epoch 611/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1839 - accuracy: 0.9251 - val_loss: 0.1726 - val_accuracy: 0.9323\n",
      "Epoch 612/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1842 - accuracy: 0.9243 - val_loss: 0.1725 - val_accuracy: 0.9318\n",
      "Epoch 613/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1848 - accuracy: 0.9243 - val_loss: 0.1726 - val_accuracy: 0.9325\n",
      "Epoch 614/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1830 - accuracy: 0.9255 - val_loss: 0.1727 - val_accuracy: 0.9318\n",
      "Epoch 615/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1844 - accuracy: 0.9247 - val_loss: 0.1724 - val_accuracy: 0.9325\n",
      "Epoch 616/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1839 - accuracy: 0.9241 - val_loss: 0.1724 - val_accuracy: 0.9317\n",
      "Epoch 617/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1831 - accuracy: 0.9248 - val_loss: 0.1727 - val_accuracy: 0.9320\n",
      "Epoch 618/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1835 - accuracy: 0.9251 - val_loss: 0.1722 - val_accuracy: 0.9325\n",
      "Epoch 619/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1835 - accuracy: 0.9247 - val_loss: 0.1718 - val_accuracy: 0.9323\n",
      "Epoch 620/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1824 - accuracy: 0.9249 - val_loss: 0.1722 - val_accuracy: 0.9315\n",
      "Epoch 621/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1824 - accuracy: 0.9250 - val_loss: 0.1715 - val_accuracy: 0.9314\n",
      "Epoch 622/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1826 - accuracy: 0.9255 - val_loss: 0.1718 - val_accuracy: 0.9319\n",
      "Epoch 623/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1823 - accuracy: 0.9256 - val_loss: 0.1714 - val_accuracy: 0.9326\n",
      "Epoch 624/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1828 - accuracy: 0.9253 - val_loss: 0.1713 - val_accuracy: 0.9317\n",
      "Epoch 625/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1822 - accuracy: 0.9264 - val_loss: 0.1707 - val_accuracy: 0.9327\n",
      "Epoch 626/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1821 - accuracy: 0.9259 - val_loss: 0.1709 - val_accuracy: 0.9327\n",
      "Epoch 627/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1811 - accuracy: 0.9260 - val_loss: 0.1704 - val_accuracy: 0.9328\n",
      "Epoch 628/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1819 - accuracy: 0.9249 - val_loss: 0.1713 - val_accuracy: 0.9316\n",
      "Epoch 629/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1829 - accuracy: 0.9247 - val_loss: 0.1707 - val_accuracy: 0.9318\n",
      "Epoch 630/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1810 - accuracy: 0.9263 - val_loss: 0.1708 - val_accuracy: 0.9330\n",
      "Epoch 631/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1819 - accuracy: 0.9256 - val_loss: 0.1706 - val_accuracy: 0.9326\n",
      "Epoch 632/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1806 - accuracy: 0.9261 - val_loss: 0.1704 - val_accuracy: 0.9325\n",
      "Epoch 633/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1805 - accuracy: 0.9256 - val_loss: 0.1708 - val_accuracy: 0.9328\n",
      "Epoch 634/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1822 - accuracy: 0.9252 - val_loss: 0.1706 - val_accuracy: 0.9329\n",
      "Epoch 635/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1819 - accuracy: 0.9257 - val_loss: 0.1703 - val_accuracy: 0.9340\n",
      "Epoch 636/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1800 - accuracy: 0.9270 - val_loss: 0.1702 - val_accuracy: 0.9340\n",
      "Epoch 637/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1822 - accuracy: 0.9248 - val_loss: 0.1704 - val_accuracy: 0.9326\n",
      "Epoch 638/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1809 - accuracy: 0.9257 - val_loss: 0.1702 - val_accuracy: 0.9328\n",
      "Epoch 639/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1788 - accuracy: 0.9262 - val_loss: 0.1697 - val_accuracy: 0.9330\n",
      "Epoch 640/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1808 - accuracy: 0.9260 - val_loss: 0.1695 - val_accuracy: 0.9327\n",
      "Epoch 641/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1803 - accuracy: 0.9267 - val_loss: 0.1693 - val_accuracy: 0.9333\n",
      "Epoch 642/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1792 - accuracy: 0.9266 - val_loss: 0.1696 - val_accuracy: 0.9326\n",
      "Epoch 643/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1802 - accuracy: 0.9273 - val_loss: 0.1696 - val_accuracy: 0.9328\n",
      "Epoch 644/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1801 - accuracy: 0.9262 - val_loss: 0.1692 - val_accuracy: 0.9329\n",
      "Epoch 645/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1804 - accuracy: 0.9252 - val_loss: 0.1689 - val_accuracy: 0.9335\n",
      "Epoch 646/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1795 - accuracy: 0.9266 - val_loss: 0.1688 - val_accuracy: 0.9334\n",
      "Epoch 647/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1793 - accuracy: 0.9270 - val_loss: 0.1686 - val_accuracy: 0.9340\n",
      "Epoch 648/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1792 - accuracy: 0.9263 - val_loss: 0.1692 - val_accuracy: 0.9341\n",
      "Epoch 649/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1804 - accuracy: 0.9260 - val_loss: 0.1696 - val_accuracy: 0.9337\n",
      "Epoch 650/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1802 - accuracy: 0.9263 - val_loss: 0.1691 - val_accuracy: 0.9333\n",
      "Epoch 651/700\n",
      "704/704 [==============================] - 6s 9ms/step - loss: 0.1772 - accuracy: 0.9274 - val_loss: 0.1689 - val_accuracy: 0.9333\n",
      "Epoch 652/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1808 - accuracy: 0.9244 - val_loss: 0.1686 - val_accuracy: 0.9331\n",
      "Epoch 653/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1798 - accuracy: 0.9263 - val_loss: 0.1686 - val_accuracy: 0.9340\n",
      "Epoch 654/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1790 - accuracy: 0.9262 - val_loss: 0.1680 - val_accuracy: 0.9333\n",
      "Epoch 655/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1798 - accuracy: 0.9265 - val_loss: 0.1683 - val_accuracy: 0.9331\n",
      "Epoch 656/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1808 - accuracy: 0.9253 - val_loss: 0.1683 - val_accuracy: 0.9332\n",
      "Epoch 657/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1789 - accuracy: 0.9264 - val_loss: 0.1684 - val_accuracy: 0.9338\n",
      "Epoch 658/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1780 - accuracy: 0.9261 - val_loss: 0.1679 - val_accuracy: 0.9336\n",
      "Epoch 659/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1779 - accuracy: 0.9265 - val_loss: 0.1685 - val_accuracy: 0.9330\n",
      "Epoch 660/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1772 - accuracy: 0.9276 - val_loss: 0.1680 - val_accuracy: 0.9325\n",
      "Epoch 661/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1791 - accuracy: 0.9267 - val_loss: 0.1680 - val_accuracy: 0.9329\n",
      "Epoch 662/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1783 - accuracy: 0.9268 - val_loss: 0.1677 - val_accuracy: 0.9336\n",
      "Epoch 663/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1777 - accuracy: 0.9270 - val_loss: 0.1677 - val_accuracy: 0.9341\n",
      "Epoch 664/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1779 - accuracy: 0.9268 - val_loss: 0.1674 - val_accuracy: 0.9347\n",
      "Epoch 665/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1780 - accuracy: 0.9269 - val_loss: 0.1675 - val_accuracy: 0.9341\n",
      "Epoch 666/700\n",
      "704/704 [==============================] - 5s 8ms/step - loss: 0.1780 - accuracy: 0.9268 - val_loss: 0.1677 - val_accuracy: 0.9342\n",
      "Epoch 667/700\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.1776 - accuracy: 0.9275 - val_loss: 0.1670 - val_accuracy: 0.9335\n",
      "Epoch 668/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1766 - accuracy: 0.9279 - val_loss: 0.1670 - val_accuracy: 0.9342\n",
      "Epoch 669/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1769 - accuracy: 0.9274 - val_loss: 0.1670 - val_accuracy: 0.9332\n",
      "Epoch 670/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1764 - accuracy: 0.9279 - val_loss: 0.1670 - val_accuracy: 0.9343\n",
      "Epoch 671/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1763 - accuracy: 0.9281 - val_loss: 0.1670 - val_accuracy: 0.9344\n",
      "Epoch 672/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1767 - accuracy: 0.9270 - val_loss: 0.1668 - val_accuracy: 0.9346\n",
      "Epoch 673/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1757 - accuracy: 0.9280 - val_loss: 0.1669 - val_accuracy: 0.9346\n",
      "Epoch 674/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1747 - accuracy: 0.9290 - val_loss: 0.1669 - val_accuracy: 0.9341\n",
      "Epoch 675/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1766 - accuracy: 0.9273 - val_loss: 0.1665 - val_accuracy: 0.9342\n",
      "Epoch 676/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1746 - accuracy: 0.9279 - val_loss: 0.1667 - val_accuracy: 0.9332\n",
      "Epoch 677/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1764 - accuracy: 0.9279 - val_loss: 0.1670 - val_accuracy: 0.9336\n",
      "Epoch 678/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1763 - accuracy: 0.9275 - val_loss: 0.1664 - val_accuracy: 0.9344\n",
      "Epoch 679/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1758 - accuracy: 0.9282 - val_loss: 0.1660 - val_accuracy: 0.9340\n",
      "Epoch 680/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1755 - accuracy: 0.9275 - val_loss: 0.1661 - val_accuracy: 0.9342\n",
      "Epoch 681/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1759 - accuracy: 0.9281 - val_loss: 0.1664 - val_accuracy: 0.9346\n",
      "Epoch 682/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1761 - accuracy: 0.9272 - val_loss: 0.1661 - val_accuracy: 0.9338\n",
      "Epoch 683/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1749 - accuracy: 0.9290 - val_loss: 0.1665 - val_accuracy: 0.9341\n",
      "Epoch 684/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1737 - accuracy: 0.9297 - val_loss: 0.1663 - val_accuracy: 0.9350\n",
      "Epoch 685/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1763 - accuracy: 0.9276 - val_loss: 0.1663 - val_accuracy: 0.9347\n",
      "Epoch 686/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1752 - accuracy: 0.9278 - val_loss: 0.1657 - val_accuracy: 0.9338\n",
      "Epoch 687/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1766 - accuracy: 0.9274 - val_loss: 0.1662 - val_accuracy: 0.9343\n",
      "Epoch 688/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1742 - accuracy: 0.9288 - val_loss: 0.1662 - val_accuracy: 0.9339\n",
      "Epoch 689/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1751 - accuracy: 0.9284 - val_loss: 0.1655 - val_accuracy: 0.9349\n",
      "Epoch 690/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1754 - accuracy: 0.9291 - val_loss: 0.1655 - val_accuracy: 0.9356\n",
      "Epoch 691/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1746 - accuracy: 0.9280 - val_loss: 0.1654 - val_accuracy: 0.9348\n",
      "Epoch 692/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1749 - accuracy: 0.9284 - val_loss: 0.1655 - val_accuracy: 0.9345\n",
      "Epoch 693/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1751 - accuracy: 0.9279 - val_loss: 0.1654 - val_accuracy: 0.9343\n",
      "Epoch 694/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1755 - accuracy: 0.9282 - val_loss: 0.1650 - val_accuracy: 0.9352\n",
      "Epoch 695/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1747 - accuracy: 0.9277 - val_loss: 0.1652 - val_accuracy: 0.9353\n",
      "Epoch 696/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1737 - accuracy: 0.9290 - val_loss: 0.1648 - val_accuracy: 0.9340\n",
      "Epoch 697/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1751 - accuracy: 0.9280 - val_loss: 0.1649 - val_accuracy: 0.9338\n",
      "Epoch 698/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1726 - accuracy: 0.9299 - val_loss: 0.1645 - val_accuracy: 0.9350\n",
      "Epoch 699/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1738 - accuracy: 0.9289 - val_loss: 0.1643 - val_accuracy: 0.9348\n",
      "Epoch 700/700\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1731 - accuracy: 0.9288 - val_loss: 0.1643 - val_accuracy: 0.9348\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=x_train2,\n",
    "    y=y_train2,\n",
    "    epochs=700,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=128,\n",
    "#     callbacks=[cp_callback, tensorboard_callback]\n",
    "    \n",
    ")\n",
    "savingResults(name = 'ResNet4', value = history.history)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot history: MAE\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(history.history['accuracy'], label='accuracy (traning data)')\n",
    "plt.plot(history.history['val_accuracy'], label='accuracy (validation data)')\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('Accuracy value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(history.history['loss'], label='categorical_entropy (training data)')\n",
    "plt.plot(history.history['val_loss'], label='categorical_entropy (validation data)')\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir tensorboard_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "savingResults(name = 'ResNet4', value = history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
